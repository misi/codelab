
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>WebRTC c0d3l4b</title>
  <link rel="icon" href="favicon/favicon-flask.ico" type="image/x-icon">
  <script src="./bower_components/webcomponentsjs/webcomponents-lite.js"></script>
  <link rel="import" href="./bower_components/codelab-components/google-codelab-elements.html">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <script type="text/javascript" src="node_modules/default-passive-events/dist/index.js"></script>
  <style is="custom-style">
    body {
      font-family: "Roboto",sans-serif;
      background: var(--google-codelab-background, --paper-grey-300);
    }
  </style>
  
</head>
<body unresolved class="fullbleed">

  <google-codelab title="WebRTC c0d3l4b"
                  environment="web"
                  feedback-link="https://github.com/misi/codelab/issues">
    
      <google-codelab-step label="Introduction" duration="5">
        <p>This codelab is focused on WebRTC Apps.</p>
<h2><strong>What is WebRTC?</strong></h2>
<table>
<tr><td colspan="1" rowspan="1"><p><strong>WebRTC is</strong></p>
<ul>
<li>An open source project</li>
<li>A new set of protocols, protocol framework</li>
<li>Working groups in standardization bodies (IETF, W3C)</li>
<li>A new market </li>
<li>Etc.</li>
</ul>
<p><strong>WebRTC&#39;s Mission is to </strong></p>
<ul>
<li>Enhance the web with  Real Time Communication (RTC) capabilities, and define a simple JS API for web developers</li>
<li>Make the browser capable to act like a Video Conference (VC) terminal (Audio/Video/Data)</li>
<li>Beyond basic VC, it gives a toolkit and playground to create any brand-new unusual advanced Media Application</li>
</ul>
</td><td colspan="1" rowspan="1"><h2><img style="max-width: 181.50px" src="img/6f5abad9e3b52099.png"></h2>
</td></tr>
</table>
<h3><strong>WebRTC Official Definitions:</strong></h3>
<ul>
<li><strong>WebRTC</strong>: &#34;A framework, protocols and application programming interface that provide real time interactive voice, video and data in web browsers and other applications&#34;</li>
<li><strong>WebRTC is a free, open</strong> project that provides browsers and mobile applications with Real-Time Communications (RTC) capabilities via simple APIs. The WebRTC components have been optimized to best serve this purpose</li>
<li><strong>Mission</strong>: To enable rich, high-quality RTC applications to be developed for the browser, mobile platforms, and IoT devices, and allow them all to communicate via a common set of protocols</li>
</ul>
<h3><strong>The WebRTC Project</strong></h3>
<ul>
<li><strong>Web</strong>: <a href="https://webrtc.org" target="_blank">https://webrtc.org</a></li>
<li><strong>WebRTC Project Logo: </strong><a href="https://webrtc.org/press/" target="_blank">https://webrtc.org/press/</a></li>
</ul>
<h3><br><strong>This c0d3l4b</strong></h3>
<p>This codelab will walk you through creating your first WebRTC App, providing the theory needed to understand the JS API and protocols running under the hood , design considerations, as well as all implementation details, to ensure that your app works properly in every network conditions and environment.</p>
<h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>How to design a WebRTC App</li>
<li>How to use the basic WebRTC API-s</li>
<li>How to access a MediaDevice. e.g. How to access your WebCam&#39;s VideoStream.</li>
<li>How to set mediaStream Input and Output devices</li>
<li>How to setup a PeerConnection (PC)</li>
<li>How to setup PC for proper NAT Traversal</li>
<li>How to use a DataChannel (DC)</li>
<li>How to record a MediaStream locally</li>
</ul>
<h2><strong>What you&#39;ll need</strong></h2>
<ul>
<li>A recent version of Chrome and Firefox Browser. <br>(Note, this should work in other browsers as well.)</li>
<li>The CodeLab Samples</li>
<li>A text editor</li>
<li>SSH client</li>
<li>Basic knowledge of HTML, CSS, JavaScript.</li>
</ul>
<aside class="special"><p><strong>Last but not least</strong>: </p>
<p>This c0d3l4b is strongly inspired by Google WebRTC CodeLab!<em> (Special thx to Sam Dutton!)</em></p>
<p><a href="https://codelabs.developers.google.com" target="_blank">https://codelabs.developers.google.com</a> </p>
<p><em>And also many thanks Google for the codelab framework!</em></p>
<ul>
<li><a href="https://github.com/googlecodelabs/codelab-components" target="_blank">https://github.com/googlecodelabs/</a></li>
<li><a href="https://g.co/codelabs/guide" target="_blank">https://g.co/codelabs/guide​</a></li>
</ul>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Getting set up" duration="10">
        <h2><strong>Setup a web server with TLS to support https</strong></h2>
<ul>
<li>even on your host: Install on your host your favorite web server with a certificate from <a href="https://letsencrypt.org/" target="_blank">let&#39;s encrypt</a>.</li>
<li>Or as an easy alternative: If you use chrome you could also use web-server-for-chrome extension: <a href="https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb?hl=en" target="_blank">Install Web Server for Chrome</a></li>
</ul>
<aside class="special"><p><strong>Tip</strong>: Those who are participating in <a href="http://nws.comp-rend.hu/" target="_blank">NWS18</a> we have already created pre install VM with certificate and web server. <br>Please test it and login on your VM with your ssh client.</p>
</aside>
<h2><strong>You could Download the Sample Code</strong></h2>
<p>Click the following link to download all the code for this codelab:</p>
<p><a href="https://github.com/misi/codelab/archive/master.zip" target="_blank"><paper-button class="colored" raised><iron-icon icon="file-download"></iron-icon>Download source code</paper-button></a></p>
<p><strong>Or</strong></p>
<pre>git clone https://github.com/misi/codelab.git</pre>
<p>Unpack the zip file in your <code>web server root directory</code>. This will unpack a root folder (<code>codelab</code>), which contains one <code>lab&lt;N&gt;</code> folder for each step of this codelab, along with all of the resources you will need. It also contains this codelab web part.</p>
<p>The <code>lab&lt;N&gt;</code> folders contain the desired end state of each step of this codelab. They are there for reference. We&#39;ll be doing all our coding work in a directory called <code>work</code>.</p>
<h2><strong>Ready? =&gt; Let&#39;s start the theory lesson!</strong></h2>
<p>WebRTC is complex and could be hard to understand for a web developer at the first sight without proper understanding of the WebRTC Architecture (technologies working under the hood), therefore we try to give you an overview about such Concepts and Architectures.</p>


      </google-codelab-step>
    
      <google-codelab-step label="WebRTC Design Goals" duration="0">
        <h2><strong>Goals</strong></h2>
<ul>
<li><strong>Easy to use, Out of the box experience for the end user (</strong>Without Plugins, Without Install, Always up2date client)</li>
<li><strong>Multi platform </strong>(Even exotic platforms (Linux, BSD))</li>
<li><strong>Push the envelope</strong>: Improved Standards like Advanced congestion avoidance, Adaptive Audio Video encoding and Forward Error Correction (FEC) to reach Reliability, Fair Share Low Delay/Latency, Low  Jitter.  Advanced Noise suppression and echo cancellation etc.</li>
<li><strong>Firewall and NAT Traversal</strong> ICE(STUN/TURN)</li>
<li><strong>Focus on Security and Privacy and Identity validation by design</strong>. Encrypted Secure End to End communication, User consent before access any MediaDevice(WebCam) to avoid any fingerprinting (as possible)</li>
<li><strong>Open Source Native Implementation</strong> (for browser vendors and beyond browsers)</li>
<li><strong>Open Standard</strong> (W3C, IETF)</li>
<li><strong>Interwork with any Signaling</strong></li>
<li><strong>Backward compatibility</strong> in WebRTC 1.0  (e.g. Offer/Answer, SDP, G.711 audio codec, DTMF)</li>
</ul>
<h2><strong>Base components:</strong></h2>
<ul>
<li><strong>GetUserMedia</strong> (GuM): Grab MediaStream from a MediaDevice</li>
<li><strong>PeerConnection</strong> (PC): Establish and Maintain Peer to Peer Media Connection</li>
<li><strong>DataChannel</strong>(DC): P2P Data connection on top of PeerConnection</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Standardization" duration="5">
        <h2><strong>Standardization bodies</strong></h2>
<table>
<tr><td colspan="1" rowspan="1"><ul>
<li>World Wide Web Consortium</li>
</ul>
</td><td colspan="1" rowspan="1"><p><img style="max-width: 58.00px" src="img/d009528c9eccaed2.png"></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><ul>
<li>Internet Engineering Task Force</li>
</ul>
</td><td colspan="1" rowspan="1"><p><img style="max-width: 83.31px" src="img/a25889a846cf8ec9.png"></p>
</td></tr>
</table>
<h2><strong>WebRTC 1.0</strong></h2>
<ul>
<li><strong>W3C</strong> WebRTC Working Group</li>
<li><strong>IETF</strong> rtcweb, rmcat, mmusic, avtcore, ice, tram, perc Working Groups</li>
</ul>
<h2><strong>WebRTC NV (In progress)</strong></h2>
<ul>
<li>QUIC transport for DataChannel/(Media?)</li>
<li>More ORTC like deeper API</li>
<li>No more Session Description Protocol (SDP)</li>
<li>More control on ICE Agent</li>
<li>Scalable Video Codec (SVC)</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="MediaStream MediaTrack" duration="5">
        <p><img style="max-width: 624.00px" src="img/bb08b77db08bffa1.png"></p>
<p>From <a href="https://w3c.github.io/mediacapture-main/#stream-api" target="_blank">mediacapture spec</a>:  </p>
<ul>
<li>The MediaStreamTrack object represents media of a single type that originates from one media source in the User Agent, e.g. video produced by a web camera. A MediaStream is used to group several MediaStreamTrack objects into one unit that can be recorded or rendered in a media element.&#34;</li>
<li>All tracks in a MediaStream are intended to be synchronized when rendered. Different MediaStream objects do not need to be synchronized.</li>
<li>A single MediaStreamTrack can represent multi-channel content, such as stereo or 5.1 audio or stereoscopic video, where the channels have a well defined relationship to each other. Information about channels might be exposed through other APIs, such as [<a href="https://www.w3.org/TR/webaudio/" target="_blank">WEBAUDIO</a>].</li>
</ul>
<h2><strong>Codecs</strong></h2>
<h3><strong>Mandatory to Implement Audio codec</strong></h3>
<ul>
<li>G711 (backward compatibility)</li>
<li>Opus (48 kHz: fullband codec, both for music and speech)</li>
</ul>
<h3><strong>Mandatory to Implement Video codecs</strong></h3>
<p>It took a long time to reach consensus in the IETF RTCWEB workgroup (&#34;Codec war..&#34;)</p>
<ul>
<li>VP8 vs H.264</li>
<li>(VP9 vs H.265)</li>
</ul>
<h4>Alliance for Open Media</h4>
<ul>
<li>AOMedia Video 1 (AV1) development</li>
<li>Amazon, Cisco, Google, Intel, Microsoft, Mozilla, Netflix, etc.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="History" duration="5">
        <p><img style="max-width: 624.00px" src="img/a0c21556f77b20aa.png"></p>
<h2>The beginning</h2>
<ul>
<li>2009 - Google Chrome Team Idea</li>
<li>2010 Summer - IETF 98 Informal lunch (Google, Microsoft, Apple, Mozilla, Skype, Ericsson,etc.)</li>
<li>2010 October - RTC Web Workshop <a href="http://rtc-web.alvestrand.com/" target="_blank">http://rtc-web.alvestrand.com/</a></li>
<li>2011 January - Google Global IP Solution (GIPS) acquired</li>
<li>2011 May - W3C WebRTC WG started officially</li>
<li>2011 June - Googe Announce WebRTC project(based on GIPS) and chrome integration</li>
<li>2011 Nov - Chrome 23 WebRTC support</li>
</ul>
<h2>Early birds</h2>
<ul>
<li>2013 January - Firefox 20 first WebRTC support (only GuM)</li>
<li>2013 February - Chrome Mozilla first call interoperability</li>
<li>2013 July - Chrome for Android support</li>
<li>2013 September - Firefox for Android support</li>
<li>2013 October - Open H.264 Cisco (Mozilla)</li>
<li>2013 October - Opera 18 Beta WebRTC debut</li>
</ul>
<h2>Onboarding on webRTC train</h2>
<ul>
<li>2014 September - OpenWebRTC (Ericsson)</li>
<li>2014 October - Microsoft Edge ORTC Announcement</li>
<li>2014 November - Consensus on Mandatory to Implement Video Codecs :-)</li>
<li>2015 September - Microsoft Edge ORTC/WebRTC support</li>
<li>2015 November - Mozilla Canvas CaptureStream</li>
<li>2016 January - VP9 Chrome</li>
<li>2016 April - ICE Restart Firefox 48</li>
</ul>
<h2>Nowadays</h2>
<ul>
<li>2017 June - Safari 11 WebRTC Support</li>
<li>2017 October - KITE WebRTC platform test</li>
<li>2017 October - Third Party Audio Codec Support</li>
<li>2017 November - WebRTC PeerConnection CR (W3C)</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Mind the Gap!" duration="0">
        <p>Duration: 5:00</p>
<p><img style="max-width: 624.00px" src="img/bccbe1f1d373bd49.png"></p>
<p><strong>Image Source</strong>: <a href="http://art.fritsahlefeldt.com/photo/2414/Mind-the-gap-with-text-Color-illustration.html" target="_blank">http://art.fritsahlefeldt.com/photo/2414/Mind-the-gap-with-text-Color-illustration.html</a></p>
<h2><strong>Adapter.js</strong></h2>
<p><strong>Standardization is a moving target! <br></strong>To build world consensus takes time. :-)  Webrtc 1.0 standardization has started in 2011, and it still has not reached the Draft Recommendation status. Hopefully, it will reach in Q4 2018 (according the current roadmap). Standard is moving target, and implementation fall behind the standardization and Web Application based on it may also fall behind the implementation. All in all, some glue/shim layer is needed.</p>
<h3><strong>Mind the gap between</strong></h3>
<ul>
<li>Standard and Browser Implementations</li>
<li>Between bowser and browser implementations</li>
<li>Application and Standard</li>
</ul>
<p>The adapter.js is a shim to insulate apps from spec changes and prefix differences.<br>(Prefixes: moz, webkit)</p>
<ul>
<li><a href="https://github.com/webrtc/adapter" target="_blank">https://github.com/webrtc/adapter</a></li>
<li><a href="https://webrtc.org/web-apis/interop" target="_blank">https://webrtc.org/web-apis/interop/</a></li>
</ul>
<h2><strong>Breaking Changes</strong></h2>
<ul>
<li>Chrome and Firefox adds deprecation warnings</li>
<li>Carefully age out, pull down not too soon</li>
</ul>
<h3><strong>Changes</strong></h3>
<ul>
<li>Async API =&gt; Move from callbacks, forward to Promises</li>
</ul>
<aside class="warning"><p><strong>Warning</strong>! </p>
<p>Only read further if you already familiar with WebRTC. Beginners could safely skip this part of the codelab, and jump to the next step.</p>
</aside>
<h4>Media Capture Changes: </h4>
<p><strong>MediaDevice selection, detection on changes (discovery)</strong></p>
<ul>
<li><strong>Old</strong>: <code>navigator.getUserMedia</code> is deprecated</li>
<li><strong>New</strong>: <code>navigator.mediaDevices.getUserMedia</code></li>
</ul>
<p><strong>Media source</strong></p>
<ul>
<li><strong>Old</strong>: <code>video.createObjectURL</code> is deprecated</li>
<li><strong>New</strong>: <code>video.srcObject</code></li>
</ul>
<h3><strong>Constraint changed</strong></h3>
<p><strong>Legacy deprecated Constraint</strong></p>
<pre><code>{
  mandatory: {
    width: { min: 640, max:1920 }
  }, 
  optional: [{ width: 1280 }]
}</code></pre>
<p><strong>New modern Constraint</strong></p>
<pre><code>{width: { min:1024, ideal: 1280, max: 1920 }}</code></pre>
<ul>
<li>Chrome constraints are deprecated</li>
<li>&#34;optional&#34; renamed to &#34;advanced&#34;</li>
</ul>
<h3><strong>Stats Changes</strong></h3>
<p><strong>Legacy deprecated Stats</strong></p>
<pre><code>pc.getStats(function(stats){
      Object.keys(stats).forEach(key =&gt;...)
   }
)</code></pre>
<p><strong>New modern Stats (promise)</strong></p>
<pre><code>pc.getStats().then(stats =&gt;stats.forEach(value=&gt;...)</code></pre>
<h3><strong>Streams =&gt; Tracks</strong></h3>
<p>Manipulating (replacing tracks) after added a stream to peerconnection makes confusion, so add tracks instead of streams to peerconnection.</p>
<p><strong>addStream is deprecated</strong></p>
<ul>
<li><strong>Old</strong>: <code>pc.addStream(stream)</code></li>
<li><strong>New</strong>: <code>stream.forEach(track =&gt; pc.addTrack(track,stream))</code></li>
</ul>
<p><strong>getLocalStreams is deprecated</strong></p>
<ul>
<li><strong>Old</strong>: <code>var streams = pc.getLocalStreams();</code></li>
<li><strong>New</strong>: <code>var senders = pc.getSenders();</code></li>
</ul>
<aside class="special"><p><strong>Tip:</strong></p>
<p>For more details see Jan-Ivar&#39;s presentation: <a href="https://www.crowdcast.io/e/webrtcstandards13" target="_blank">https://www.crowdcast.io/e/webrtcstandards13</a></p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="WebRTC 1.0 Architecture" duration="5">
        <h3><strong>Protocol Stack</strong></h3>
<p>WebRTC supports both IPv4 and IPv6 protocol. ICE helps in the smooth transition. </p>
<p>For the Real Time Communication the UDP transport is more ideal than TCP, but it could fallback to TCP. </p>
<p>On top of this transport layer, the STUN helps in NAT/Firewall traversal. The other protocols, like  SRTP and DTLS provides the end-to-end encrypted communication channel. SRTP for media, and DTLS for SRTP keying and Data. SCTP on top of it provides multiple flows, and configurable reliability and delivery parameters.<br>Please notice that WebRTC intention is to happen all communication in encrypted form, and so encryption is mandatory on media and data channel(SRTP/DTLS).</p>
<p><img style="max-width: 520.00px" src="img/ea08a380495f9f3e.png"></p>
<p><strong>Image Source</strong>: <a href="https://commons.wikimedia.org/wiki/File:Media-exchange-for-WebRTC.svg" target="_blank">https://commons.wikimedia.org/wiki/File:Media-exchange-for-WebRTC.svg</a></p>
<h2><strong>WebRTC native Architecture</strong></h2>
<p><img style="max-width: 624.00px" src="img/fcdec68b59f9447d.png"></p>
<p><strong>Image Source</strong>: <a href="https://webrtc.org/architecture/" target="_blank">https://webrtc.org/architecture/</a></p>
<h2><strong>WebRTC Trapezoid</strong></h2>
<h3><strong>Direct Peer to Peer Connection</strong></h3>
<p><img style="max-width: 624.00px" src="img/149faeda7a820cf4.png"></p>
<p>(For simplification on the picture above the WebServer contains the signaling server too!)</p>
<aside class="special"><p><strong>Note</strong>:</p>
<p>Direct Browser to Browser connection is prefered by default to keep the end to end delay low. ICE preferes by default TURN in last resort.</p>
<p>Of course there are other reasonable preferences, like more reliable connection first or short connection establishment time, that may override ICE default behavior and prefer TURN first.</p>
</aside>
<h3><strong>Address and Port-Dependent Mapping &amp; Address and Port-Dependent Filtering (Symmetric) NAT</strong></h3>
<p><img style="max-width: 624.00px" src="img/a090a6dbe2aec127.png"></p>
<p>(For simplification on the picture above the WebServer contains the signaling server too!)</p>


      </google-codelab-step>
    
      <google-codelab-step label="Why NAT/Firewall traversal needed in WebRTC?" duration="0">
        <p>Mainly because usage of Network Address Translation(NAT) and Packet Filters made difficult (or impossible) the direct Peer to Peer communication. As we will see in the next step, Interactive Connection Establishment protocol (ICE) has been designed to solve these problems.</p>
<h2><strong>Firewall / Packet Filter</strong></h2>
<p>For Media communication the Real-time Transport Protocol(RTP) use random port numbers. We need to find a ip:port pair that is not filtered between the two peers. ICE have to run 2 way checks on the candidate pairs, on the &#34;5 Tuple&#34; transport connections, to make sure that the communication channel has established and working properly. The transport connection needs to work properly before any Real-time communication could be started on top of it.</p>
<h2><strong>Network Address Translation(NAT)</strong></h2>
<p>In this section we focus on NAT. Let&#39;s look it little bit closer.</p>
<p>The NAT behavior standardization started much later than the first NAT implementation existed. NAT traversal is complex. It is confusing mainly because of the so big variety of different NAT behaviors and types. ICE have to deal with any topology, and so any types and levels of NATs!</p>
<aside class="warning"><p><strong>Warning</strong>! </p>
<p>Only read further if you already familiar with NAT and Firewall traversal.  Beginners could safely skip this part of the codelab, and jump to the next step.</p>
</aside>
<h2><strong>NAT Behaviors / Types</strong></h2>
<h3><strong>RFC 3489</strong></h3>
<p>The <strong>RFC 3489,</strong> also known as &#34;<strong>classic STUN</strong>&#34; defined four NAT types</p>
<ul>
<li>Full Cone</li>
<li>Restricted Cone</li>
<li>Port Restricted Conde</li>
</ul>
<h2><strong>RFC 4787 NAT behavioral Requirements for UDP</strong></h2>
<p>RFC 4787 defined much much more fine grained classification of NATs.</p>
<h3><strong>RFC 4787 main class definitions:</strong></h3>
<p><strong>Mapping</strong></p>
<ul>
<li>Endpoint Independent Mapping</li>
<li>Address-Dependent Mapping</li>
<li>Address and Port-Dependent Mapping</li>
</ul>
<p><strong>Filtering</strong></p>
<ul>
<li>Endpoint Independent Filtering</li>
<li>Address-Dependent Filtering</li>
<li>Address and Port-Dependent Filtering</li>
</ul>
<p>And it defines much more NAT behaviors too.</p>
<p><img style="max-width: 624.00px" src="img/8308d0c42ae77d7c.png"></p>
<p><strong>Image Source</strong>: <a href="https://www.netmanias.com/en/?m=view&id=techdocs&no=6065" target="_blank">https://www.netmanias.com/en/?m=view&amp;id=techdocs&amp;no=6065</a></p>
<h2><img style="max-width: 624.00px" src="img/62ad5490047f0f38.png"></h2>
<p><strong>Image Source</strong>: <a href="https://www.netmanias.com/ko/?m=view&id=blog&no=6263" target="_blank">https://www.netmanias.com/ko/?m=view&amp;id=blog&amp;no=6263</a></p>
<h2><strong>NAT Behavior Discovery (RFC5780)</strong></h2>
<p>RFC5780 is a STUN protocol extension.</p>
<h3><strong>Mapping Discovery</strong></h3>
<ul>
<li>TEST I (Primary IP, Primary Port)</li>
<li>TEST II (Alternate IP, Primary Port)</li>
<li>TEST III (Alternate IP, Alternate Port)</li>
</ul>
<p><img style="max-width: 469.00px" src="img/c383b757098fe421.png"></p>
<p><strong>Image Source</strong>: <a href="http://www.netmanias.com/en/post/techdocs/6067/nat-stun/nat-behavior-discovery-using-stun-rfc-5780" target="_blank">http://www.netmanias.com/en/post/techdocs/6067/nat-stun/nat-behavior-discovery-using-stun-rfc-5780</a></p>
<h3><strong>Filtering</strong></h3>
<ul>
<li>TEST I (Primary IP, Primary Port)</li>
<li>TEST II (Change Request IP and Port)</li>
<li>TEST III (Change Request Port)</li>
</ul>
<p><img style="max-width: 465.00px" src="img/3cfca2b53970b434.png"></p>
<p><strong>Image Source</strong>: <a href="http://www.netmanias.com/en/post/techdocs/6067/nat-stun/nat-behavior-discovery-using-stun-rfc-5780" target="_blank">http://www.netmanias.com/en/post/techdocs/6067/nat-stun/nat-behavior-discovery-using-stun-rfc-5780</a></p>
<aside class="special"><p><strong>Thanks to www.netmanias.com for the nice illustrations!</strong></p>
<p>Read for a more detailed step by step explanation with similar nice graphs:</p>
<ul>
<li><a href="http://www.netmanias.com/en/post/techdocs/6067/nat-stun/nat-behavior-discovery-using-stun-rfc-5780" target="_blank">http://www.netmanias.com/en/post/techdocs/6067/nat-stun/nat-behavior-discovery-using-stun-rfc-5780</a></li>
<li><a href="https://www.netmanias.com/en/?m=view&id=techdocs&no=6065" target="_blank">https://www.netmanias.com/en/?m=view&amp;id=techdocs&amp;no=6065</a></li>
<li><a href="https://www.netmanias.com/ko/?m=view&id=blog&no=6263" target="_blank">https://www.netmanias.com/ko/?m=view&amp;id=blog&amp;no=6263</a></li>
</ul>
</aside>
<h3><strong>coTURN natdiscovery utility</strong></h3>
<p><img style="max-width: 624.00px" src="img/5159f9e65f6a5e50.png"></p>
<pre>$ turnutils_natdiscovery -f -m rfc5780.turn.geant.org
...
========================================
NAT with Address and Port Dependent Mapping!
========================================
...
========================================
NAT with Address and Port Dependent Filtering!
========================================
$</pre>
<aside class="special"><p><strong>Tip</strong>:</p>
<p>See coTURN turnutils_natdiscovery README for options <a href="https://github.com/coturn/coturn/blob/master/README.turnutils" target="_blank">https://github.com/coturn/coturn/blob/master/README.turnutils</a></p>
</aside>
<p>NAT discovery in browser:</p>
<p>We reuse the same idea here that we used earlier in RFC 5780 NAT behavior discovery.</p>
<p>If a NAT translates traffic originating from the same internal port to different external source ports, because of the different destination ip:port (in our case different destination STUN servers), then</p>
<p>It could be: </p>
<ul>
<li>Address Dependent Mapping</li>
<li>Address and Port Dependent Mapping</li>
</ul>
<p><br>See WebRTC h4cks article about howto discover a symmetric NAT: </p>
<ul>
<li><a href="https://webrtchacks.com/symmetric-nat/" target="_blank">https://webrtchacks.com/symmetric-nat/</a></li>
</ul>
<p><img style="max-width: 624.00px" src="img/344644acb209b784.png"></p>
<aside class="special"><p><strong>Notice</strong>: coTURN utility gives much detailed and more precise and reliable information about the NAT behaviour than the browser test could do.</p>
</aside>
<h2><strong>NAT behaviors in the real-world</strong></h2>
<aside class="warning"><p><strong>Warning: </strong></p>
<p><strong>Mind the gap</strong> between RFC 4787 behaviour model and  the real-world NAT implementations! Not every implementation behavior fits perfectly in the defined categories.</p>
</aside>
<p>I have collected the NAT behaviors in the following table. In this table you could find OS/vendors/appliances, and the <strong>default</strong> NAT behavior that belongs to it. Furthermore you could find the options that could be used to modify the default behavior. </p>
<p>(These are only my experiences and test results according my actual knowledge. <a href="https://github.com/misi/codelab/issues/new" target="_blank"><em>Please correct me if you think I am wrong!</em></a>)<br></p>
<table>
<tr><td colspan="1" rowspan="1"><p>Vendor/Behavior</p>
</td><td colspan="1" rowspan="1"><p>EIM/EIF</p>
</td><td colspan="1" rowspan="1"><p>EIM/ADF</p>
</td><td colspan="1" rowspan="1"><p>EIM/APDF</p>
</td><td colspan="1" rowspan="1"><p>APDM/APDF</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>Linux /</p>
<p>Netfilter</p>
<p>(Campus)</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td><td colspan="1" rowspan="1"><p>--random</p>
<p>--random-fully</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>BSD /PF</p>
<p>(Campus)</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>static-port</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>Juniper<br>vSRX</p>
<p>(Campus)</p>
</td><td colspan="1" rowspan="1"><p>persistent-nat<br>any-remote-host</p>
</td><td colspan="1" rowspan="1"><p>persistent-nat</p>
<p>target-host</p>
</td><td colspan="1" rowspan="1"><p>persistent-nat</p>
<p>target-host-port</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>Cisco ios</p>
<p>(Campus)</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>Checkpoint 21400</p>
<p>(Campus)</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>TP-Link</p>
<p>(SOHO)</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>Mikrotik</p>
<p>RouterBOARD</p>
<p>(SOHO)</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>Lede 17.0.2 Linux</p>
<p>(SOHO)</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td><td colspan="1" rowspan="1"><p>--random</p>
<p>--random-fully</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>PF-Sense </p>
<p>BSD</p>
<p>(SOHO)</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>static-port</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>Win 10 Pro</p>
<p>(Internet Sharing)</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>macOS</p>
<p>(Internet Sharing)</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>iOS</p>
<p>(Internet Sharing)</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td></tr>
<tr><td colspan="1" rowspan="1"><p>Android</p>
<p>(Internet Sharing)</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td><td colspan="1" rowspan="1"><p><strong>Default</strong></p>
</td><td colspan="1" rowspan="1"><p>X</p>
</td></tr>
</table>
<p><strong>To clarify further the options in the table above with an example: </strong></p>
<p>In Linux case, the Netfilter‘s (iptables) <strong>default</strong> behavior is Endpoint Independent Mapping with Address and Port Dependent Filtering (EIM/APDF)</p>
<pre>iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE </pre>
<p>If you use --random  or --random-fully option, then you could change NAT behavior to Address and Port dependent Mapping with Address and Port dependent Filtering (APDM/APDF)</p>
<pre>iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE --random</pre>
<h2><strong>Port Randomization</strong></h2>
<p>Why port randomization? It is proposed solutions to  e.g. DNS cache poisoning / <a href="http://unixwiz.net/techtips/iguide-kaminsky-dns-vuln.html" target="_blank">Kaminsky dns vulnerability</a>. </p>
<p>The 5 tuple (source and destination ip port and transport protocol) Transport-Protocol Port Randomization is recommended according <a href="https://tools.ietf.org/html/rfc6056" target="_blank">RFC 6056</a>.</p>
<p>And <a href="https://tools.ietf.org/html/rfc7857" target="_blank">RFC 7857</a> updates to Network Address Translation (NAT) Behavioral Requirements according it.</p>
<p>(But even port randomization could be derandomized with fine grained attacks: <a href="https://arxiv.org/pdf/1205.5190.pdf" target="_blank">https://arxiv.org/pdf/1205.5190.pdf</a>. To avoid Kaminsky DNS vulnerability the safe way to use DNSSEC.)</p>
<h2><strong>Summary of NAT behaviors</strong></h2>
<p>According my  experiences</p>
<ul>
<li><strong>Campus/Enterprise NAT</strong>s most commonly use <strong>Port Randomization with Address and Port dependent Mapping with Address and Port dependent Filtering </strong></li>
<li><strong>SOHO NAT</strong>s most commonly use <strong>Endpoint Independent Mapping with Address and Port Dependent Filtering</strong></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="NAT/Firewall traversal &amp; ICE (STUN/TURN)" duration="15">
        <h2><img style="max-width: 624.00px" src="img/a4ab88365707a723.png"></h2>
<h2>TL;DR        </h2>
<ul>
<li>STUN is a binary protocol</li>
<li>STUN Discover Client global IP:port</li>
<li>TURN is a STUN protocol extension</li>
<li>TURN is about Allocate a global IP:port and tunnel and Relay traffic</li>
<li>ICE finds the shortest working path between two ICE agents</li>
</ul>
<aside class="special"><p><strong>Nice ICE Tutorials</strong>:</p>
<ul>
<li><a href="https://sdstrowes.co.uk/talks/20081031-ice-turn-stun-tutorial.pdf" target="_blank">https://sdstrowes.co.uk/talks/20081031-ice-turn-stun-tutorial.pdf</a></li>
<li><a href="http://www.jdrosen.net/uploads/1/5/0/0/15008848/ice-ietf-tutorial2.pptx" target="_blank">http://www.jdrosen.net/uploads/1/5/0/0/15008848/ice-ietf-tutorial2.pptx</a></li>
</ul>
</aside>
<h2><strong>STUN/TURN</strong></h2>
<h3><strong>STUN - Binding:</strong></h3>
<p><img style="max-width: 624.00px" src="img/c73944b647485a86.png"></p>
<h3><strong>TURN - Allocate</strong></h3>
<p><img style="max-width: 624.00px" src="img/59609b44fde7fdad.png"></p>
<aside class="special"><p><strong>Note</strong>: </p>
<ul>
<li>Discover your candidate: <a href="https://webrtc.github.io/samples/src/content/peerconnection/trickle-ice/" target="_blank">https://webrtc.github.io/samples/src/content/peerconnection/trickle-ice/</a></li>
</ul>
</aside>
<h2>ICE</h2>
<h3><strong>Design Goals</strong></h3>
<ul>
<li>High reliability is essential during connection establishments</li>
<li>Minimize the &#34;length&#34; of the path between clients</li>
<li>Negotiate IP protocol version (IPv4/IPV6) and preference</li>
<li>No assumption on: (Network topologies, NAT or Firewall presence, NAT behaviours)</li>
</ul>
<h3><strong>ICE Steps</strong></h3>
<ul>
<li>Discovery and Candidate gathering (Allocation)</li>
<li>Prioritisation</li>
<li>Eliminating redundant candidates</li>
<li>Exchange (SDP)</li>
<li>Connectivity Check (Binding Request + Short Term Credential)</li>
<li>Coordination (Controlling/Controlled, Nomination)</li>
<li>Communication</li>
</ul>
<h3><strong>Discovery Candidates</strong></h3>
<ul>
<li>Multiple interfaces</li>
<li>Multiple type of interface (WIFI, Mobile, LAN, VPN)</li>
<li>Multiple protocols (IPv4, IPv6)</li>
</ul>
<aside class="warning"><p><strong>Warning</strong>! </p>
<p>Only read further if you already familiar with ICE. Beginners could safely skip this part of the codelab so feel free to jump the next step.</p>
</aside>
<h3>ICE prioritization</h3>
<pre><code>priority = (2^24)*(type preference)
          +(2^8)*(local preference)
          +(2^0)*(256 - component ID) </code></pre>
<p><strong>priority (32bit)</strong></p>
<ul>
<li><strong>Type preference (8 bit): 0-126 </strong>The RECOMMENDED values are 126 for <code>host</code> candidates, 100 for <code>server reflexive</code> candidates, 110 for <code>peer reflexive</code> candidates, and 0 for <code>relayed</code> candidates.</li>
<li><strong>Local preference(16 bit):</strong> Version(IPv4/IPv6), network interfaces(VPN/LAN)</li>
<li><strong>Component ID (8 bit) 256 - component ID</strong></li>
</ul>
<h3><strong>ICE User Agent (UA) Role</strong></h3>
<ul>
<li>Controlling</li>
<li>Controlled</li>
</ul>
<p>The Controlling is the one that&#39;s sent the initial Offer. (In case of both agents are a full</p>
<p>   implementation).</p>
<h3>Pair priority formula</h3>
<p>Let </p>
<ul>
<li>G the controlling priority (Offer) </li>
<li>D the controlled priority (Answer)</li>
</ul>
<pre><code>pair priority = 2^32*MIN(G,D) + 2*MAX(G,D) + (G&gt;D?1:0)</code></pre>
<h3><strong>Foundation</strong></h3>
<p>Candidates has the same foundation and are similar when they are of the same type and obtained from the same interface and STUN or TURN server.</p>
<h3><strong>Frozen Algorithm</strong></h3>
<p>The idea is to use the results of a previous check to predict the likelihood of a future one working. </p>
<h2><strong>ICE Agent States</strong></h2>
<p><img style="max-width: 624.00px" src="img/8ad2e7ad2cd572cf.png"></p>
<p>For more details please see the ICE tutorials mentioned above.</p>
<h2><strong>Trickle ICE</strong></h2>
<p>Connection establishment time could be long if we need to wait to finish the candidate discovery. </p>
<p>Even worse, in case of any error is occuring during the discovery. Waiting for the timeouts could take long, and could cause an unacceptable very long connection establishment. </p>
<h3><strong>Establish connection faster</strong></h3>
<p>The primary idea behind it is to start ICE check as fast as we can, as soon as we discover a candidate. The only drawback is that we need to send more signaling messages. WebRTC Application nowadays use mostly Trickle ICE to establish connection.<img style="max-width: 624.00px" src="img/bc12d7ccb7c091cf.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="Multiplex/Bundle" duration="5">
        <p><img style="max-width: 624.00px" src="img/28b69f81215d06fe.png"></p>
<p>To reduce the number of connections, and so the call establishment time, the WebRTC could use two optimization:</p>
<ul>
<li>RTP/RTCP multiplex  <br><code>a=group:BUNDLE foo bar</code><br><a href="https://tools.ietf.org/html/rfc5761" target="_blank">RFC5761</a>/ <a href="https://tools.ietf.org/html/rfc8035" target="_blank">RFC8035</a><code><br></code></li>
<li>Bundle RTP (multiplex rtp streams e.g. audio+video) <br><code>a=group:BUNDLE foo bar</code><br><a href="https://tools.ietf.org/html/draft-ietf-mmusic-sdp-bundle-negotiation-47" target="_blank">https://tools.ietf.org/html/draft-ietf-mmusic-sdp-bundle-negotiation-47</a></li>
</ul>
<h2><strong>SDP example</strong></h2>
<pre><code>v=0
o=alice 2890844526 2890844526 IN IP4 atlanta.example.com
s=
c=IN IP4 atlanta.example.com
t=0 0
a=group:BUNDLE foo bar
m=audio 10000 RTP/AVP 0 8 97 
b=AS:200
a=mid:foo
a=rtcp-mux
a=rtpmap:0 PCMU/8000
a=rtpmap:8 PCMA/8000
a=rtpmap:97 iLBC/8000
a=extmap 1 urn:ietf:params:rtp-hdrext:sdes:mid
m=video 10002 RTP/AVP 31 32
b=AS:1000
a=mid:bar
a=rtcp-mux
a=rtpmap:31 H261/90000
a=rtpmap:32 MPV/90000
a=extmap 1 urn:ietf:params:rtp-hdrext:sdes:mid</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Congestion Avoidance" duration="5">
        <p>It is very important part of  WebRTC to use an intelligent congestion control algorithm, that estimates the maximum bandwidth and share the available bandwidth fairly.</p>
<p><strong>Standardization happens in IETF RMCAT working group</strong></p>
<ul>
<li>Receiver Estimated Maximum Bandwidth (REMB)</li>
<li>Sender Side Bandwidth Estimation</li>
<li>Forward Error Correction (FEC)</li>
</ul>
<p><strong>More Details</strong>:</p>
<ul>
<li><a href="http://www.rtcbits.com/2017/01/bandwidth-estimation-in-webrtc-and-new.html" target="_blank">http://www.rtcbits.com/2017/01/bandwidth-estimation-in-webrtc-and-new.html</a></li>
<li><a href="https://blog.mozilla.org/webrtc/what-is-rmcat-congestion-control" target="_blank">https://blog.mozilla.org/webrtc/what-is-rmcat-congestion-control</a>/</li>
<li><a href="https://public.boxcloud.com/d/1/MgC0Sn2Nrq-7JGAy46x2KYfGBwqTTQUu7hNq-V153kgoiOY1F_w48tsn_bsqvocMmaHon1tjDDe8aGFj0MMMbWjEbRlqvG3-mjE5wUqbxx_XyyDIH8VlGzFOL3FX9wuCaQDfTtfnFDtKBBH49bPPyjh_Vjt_QNpzWFTk2TOmWRtRQsqZ9OGvGP7wHqYhZcqWucrlgZw5eSJD8X9dsOHcDHuVWWL5AXu_pdqjEjjNqk3eiYKgMMvmvvHqxTvKumdpLN244__ibPxgLqZZyvv7zd479-SEJYGugxgTzvqqj8F02rh6N_jhA1ZyWSw5KkoQbdP62zuHlS8Vj74xBP0ZkauTA52Yt5apBjmShjsE6lgKoe3W-eMqgC_iS0oLjasqPfVT6C7fUaXl___jznddbaWWWcPilkyXWjSl5-8PBboFpL-eDnI5WCy4092yCtBzaOBlIco3g1g2gSjv6MWWmwNRbl8JGNmsvTLkaG_KY7uW9KLE617ny_3LEIsLi6srUPgT_UbLHAxn6cY5Voo3AeSsjaFXgHvycA8TB7zNPQ9jx8GlpH4DDu_uDLxKV_BE9PKrqRftURMWXp-cckMqT3-1pgpGLnol7BK_cAQH6pkm7lpGJ-OOD_TrlpxvINE_Z7OEjAPdEHA0ngNmKRCcmRan57wJ96TlLJh5kUjJMdOT7A2tIlAnTCly05khfay_RtWUnqPugv1xq7oTBW_2STeoeOjgOYT8wQpCqVSu4DnlE2pU25yj043oOVLbRhBeetxwD4Co1A10tVsUHEdkmeNBoKkBUaxdHVj_12soIviUEwjFVpsi6cn9L4rvUTADd2yizWc2fVmuibdycVTVejgsemdWh3nH4QPHcoZ-umsxFocgTN0bKxpZwypWY0aodtouH4FCVdt4lxgogbabex9cZSyoYRnluaGRXyJlODYZVk6oP2YAKmQv2ZuE61GqMKB7HA9HcT0wnwFOWLJqXaKzJX8hQsyEi1Do9r7Fbs05Y_6XPyUAiwcyf95nlFEGWuNZYjVdSnq7M_xVzRhZp4iyob_E9W0NXJGijroJNulxLgLw0NZmXPhPEegqYOIEt7C2p5teFblYdHbTmz-A2LoW2tN0SDagO-cB8GN_G4l6iBdiF-rubNkp8OMEduyHj2Z6opFkLOCdxeMPOh2JAD8hbcmWW9dv1688YOswPAHON92H173m47Xd0JIlr9zmT58Cy1RS_pjNVVXVeA../download" target="_blank">TF-WebRTC_5_Congestion_Luca.pdf</a></li>
<li><a href="https://www.callstats.io/2016/11/14/fec-congestion-control/" target="_blank">https://www.callstats.io/2016/11/14/fec-congestion-control/</a></li>
<li><a href="https://www.callstats.io/2017/10/16/acm-multimedia/" target="_blank">https://www.callstats.io/2017/10/16/acm-multimedia/</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Session Description Protocol (SDP)" duration="0">
        <p>Duration: 10 min</p>
<aside class="special"><p><strong>Tip</strong>: SDP Anatomy on webrtcH4cKS <a href="https://webrtchacks.com/sdp-anatomy" target="_blank">https://webrtchacks.com/sdp-anatomy</a></p>
</aside>
<h3><strong>Plans</strong></h3>
<p><strong>Unified Plan</strong>: </p>
<ul>
<li><a href="https://webrtcglossary.com/unified-plan" target="_blank">https://webrtcglossary.com/unified-plan</a></li>
<li><a href="https://tools.ietf.org/html/draft-roach-mmusic-unified-plan-00" target="_blank">https://tools.ietf.org/html/draft-roach-mmusic-unified-plan-00</a></li>
</ul>
<p><strong>Plan B</strong>: (Obsoleted!)</p>
<ul>
<li><a href="https://webrtcglossary.com/unified-plan" target="_blank">https://webrtcglossary.com/unified-plan</a></li>
<li><a href="https://tools.ietf.org/html/draft-uberti-rtcweb-plan-00" target="_blank">https://tools.ietf.org/html/draft-uberti-rtcweb-plan-00</a></li>
<li>Chrome / Chromium is still working the transition to Unified Plan  <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=465349" target="_blank">https://bugs.chromium.org/p/chromium/issues/detail?id=465349</a></li>
</ul>
<aside class="special"><p><strong>Plan Adapter</strong>:</p>
<p>It is very hard to polyfill plan differences, but here  is an example: <a href="https://www.npmjs.com/package/sdp-interop" target="_blank">https://www.npmjs.com/package/sdp-interop</a></p>
</aside>
<h2><strong>Example SDP</strong></h2>
<h3><strong>Offer</strong></h3>
<pre><code>v=0
o=mozilla...THIS_IS_SDPARTA-58.0.2 1392930692610468855 0 IN IP4 0.0.0.0
s=-
t=0 0
a=sendrecv
a=fingerprint:sha-256 97:73:D6:F9:B8:4C:4A:29:3B:E0:B4:3E:E6:37:F6:D0:B7:8A:88:D9:E5:D2:C4:F8:74:66:18:B7:84:18:BB:42
a=group:BUNDLE sdparta_0 sdparta_1
a=ice-options:trickle
a=msid-semantic:WMS *
m=audio 51644 UDP/TLS/RTP/SAVPF 109 9 0 8 101
c=IN IP4 193.224.69.74
a=candidate:0 1 UDP 2122252543 192.0.2.1 53693 typ host
a=candidate:4 1 TCP 2105524479 192.0.2.1 9 typ host tcptype active
a=candidate:0 2 UDP 2122252542 192.0.2.1 40157 typ host
a=candidate:4 2 TCP 2105524478 192.0.2.1 9 typ host tcptype active
a=candidate:3 1 UDP 92217087 193.224.69.74 51644 typ relay raddr 193.224.69.74 rport 51644
a=candidate:3 2 UDP 92217086 193.224.69.74 64126 typ relay raddr 193.224.69.74 rport 64126
a=sendrecv
a=end-of-candidates
a=extmap:1/sendonly urn:ietf:params:rtp-hdrext:ssrc-audio-level
a=extmap:2 urn:ietf:params:rtp-hdrext:sdes:mid
a=fmtp:109 maxplaybackrate=48000;stereo=1;useinbandfec=1
a=fmtp:101 0-15
a=ice-pwd:957d8d9d754992a1d5a7706d5cb2e1fe
a=ice-ufrag:732f8881
a=mid:sdparta_0
a=msid:{69779578-0a01-46d5-afb8-c1ce8eb8b4f7} {3b93eb2f-9bf4-4955-95d0-5379eeba3e11}
a=rtcp:64126 IN IP4 193.224.69.74
a=rtcp-mux
a=rtpmap:109 opus/48000/2
a=rtpmap:9 G722/8000/1
a=rtpmap:0 PCMU/8000
a=rtpmap:8 PCMA/8000
a=rtpmap:101 telephone-event/8000
a=setup:actpass
a=ssrc:2764815782 cname:{08b8c6e5-8963-4a02-825f-d55ddb7076ba}
m=video 51644 UDP/TLS/RTP/SAVPF 120 121 126 97
c=IN IP4 193.224.69.74
a=candidate:0 1 UDP 2122252543 192.0.2.1 55556 typ host
a=candidate:4 1 TCP 2105524479 192.0.2.1 9 typ host tcptype active
a=candidate:0 2 UDP 2122252542 192.0.2.1 42946 typ host
a=candidate:4 2 TCP 2105524478 192.0.2.1 9 typ host tcptype active
a=candidate:3 1 UDP 92217087 193.224.69.74 52200 typ relay raddr 193.224.69.74 rport 52200
a=candidate:3 2 UDP 92217086 193.224.69.74 65354 typ relay raddr 193.224.69.74 rport 65354
a=sendrecv
a=extmap:1 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time
a=extmap:2 urn:ietf:params:rtp-hdrext:toffset
a=extmap:3 urn:ietf:params:rtp-hdrext:sdes:mid
a=fmtp:126 profile-level-id=42e01f;level-asymmetry-allowed=1;packetization-mode=1
a=fmtp:97 profile-level-id=42e01f;level-asymmetry-allowed=1
a=fmtp:120 max-fs=12288;max-fr=60
a=fmtp:121 max-fs=12288;max-fr=60
a=ice-pwd:957d8d9d754992a1d5a7706d5cb2e1fe
a=ice-ufrag:732f8881
a=mid:sdparta_1
a=msid:{69779578-0a01-46d5-afb8-c1ce8eb8b4f7} {c4e521ab-ac5c-468d-bda4-102fa8c63ad1}
a=rtcp:65354 IN IP4 193.224.69.74
a=rtcp-fb:120 nack
a=rtcp-fb:120 nack pli
a=rtcp-fb:120 ccm fir
a=rtcp-fb:120 goog-remb
a=rtcp-fb:121 nack
a=rtcp-fb:121 nack pli
a=rtcp-fb:121 ccm fir
a=rtcp-fb:121 goog-remb
a=rtcp-fb:126 nack
a=rtcp-fb:126 nack pli
a=rtcp-fb:126 ccm fir
a=rtcp-fb:126 goog-remb
a=rtcp-fb:97 nack
a=rtcp-fb:97 nack pli
a=rtcp-fb:97 ccm fir
a=rtcp-fb:97 goog-remb
a=rtcp-mux
a=rtpmap:120 VP8/90000
a=rtpmap:121 VP9/90000
a=rtpmap:126 H264/90000
a=rtpmap:97 H264/90000
a=setup:actpass
a=ssrc:1307424569 cname:{08b8c6e5-8963-4a02-825f-d55ddb7076ba}</code></pre>
<h3><strong>Answer</strong></h3>
<pre><code>v=0
o=mozilla...THIS_IS_SDPARTA-58.0.2 8465178051030770266 0 IN IP4 0.0.0.0
s=-
t=0 0
a=sendrecv
a=fingerprint:sha-256 F7:8B:D4:93:EC:66:10:17:A7:88:E2:DB:E2:02:D8:A8:0E:78:0C:47:D1:CF:AC:A8:4A:7F:B0:F8:9C:22:54:DD
a=group:BUNDLE sdparta_0 sdparta_1
a=ice-options:trickle
a=msid-semantic:WMS *
m=audio 9 UDP/TLS/RTP/SAVPF 109 101
c=IN IP4 0.0.0.0
a=candidate:0 1 UDP 2122252543 198.51.100.65 39578 typ host
a=candidate:4 1 UDP 2122187007 198.51.100.177 34202 typ host
a=candidate:8 1 TCP 2105524479 198.51.100.65 9 typ host tcptype active
a=candidate:9 1 TCP 2105458943 198.51.100.177 9 typ host tcptype active
a=candidate:3 1 UDP 92217087 193.224.69.74 55675 typ relay raddr 193.224.69.74 rport 55675
a=sendrecv
a=extmap:2 urn:ietf:params:rtp-hdrext:sdes:mid
a=fmtp:109 maxplaybackrate=48000;stereo=1;useinbandfec=1
a=fmtp:101 0-15
a=ice-pwd:36acccb528a6c8502e42656cc6c7b8cd
a=ice-ufrag:14888916
a=mid:sdparta_0
a=msid:{9cc1f70c-c78b-44b4-86fa-fcd82c530b1e} {4662f9ed-4a45-4f9f-964d-4ffff5535e5f}
a=rtcp-mux
a=rtpmap:109 opus/48000/2
a=rtpmap:101 telephone-event/8000
a=setup:active
a=ssrc:1899896363 cname:{0cc05c74-02a9-4474-9885-9ea7674b8299}
m=video 9 UDP/TLS/RTP/SAVPF 120
c=IN IP4 0.0.0.0
a=sendrecv
a=extmap:1 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time
a=extmap:2 urn:ietf:params:rtp-hdrext:toffset
a=extmap:3 urn:ietf:params:rtp-hdrext:sdes:mid
a=fmtp:120 max-fs=12288;max-fr=60
a=ice-pwd:36acccb528a6c8502e42656cc6c7b8cd
a=ice-ufrag:14888916
a=mid:sdparta_1
a=msid:{9cc1f70c-c78b-44b4-86fa-fcd82c530b1e} {425480c1-460a-4b92-8b43-59cc59062d0d}
a=rtcp-fb:120 nack
a=rtcp-fb:120 nack pli
a=rtcp-fb:120 ccm fir
a=rtcp-fb:120 goog-remb
a=rtcp-mux
a=rtpmap:120 VP8/90000
a=setup:active
a=ssrc:377924797 cname:{0cc05c74-02a9-4474-9885-9ea7674b8299}</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Offer Answer" duration="5">
        <h2><strong>WebRTC Offer/Answer Model</strong></h2>
<p><img style="max-width: 624.00px" src="img/4f1ff8d0dc38445c.png"></p>
<h2><strong>PeerConnection States</strong></h2>
<p><img style="max-width: 600.00px" src="img/eddf66e8239393c2.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="WebRTC Security Architecture" duration="5">
        <h2><strong>GetUserMedia</strong></h2>
<ul>
<li>Secure User Interface opt-in (e.g. Camera, audio access)</li>
<li>User can allow/deny audio video source usage</li>
</ul>
<aside class="special"><p><strong>Tip</strong>! See EKR IETF presentation for detailed more information: <a href="http://www.ietf.org/proceedings/82/slides/rtcweb-13.pdf" target="_blank">http://www.ietf.org/proceedings/82/slides/rtcweb-13.pdf</a></p>
</aside>
<h2>Offer Answer <code>without</code><strong> Identity Check</strong></h2>
<p><img style="max-width: 624.00px" src="img/31562214b7e28759.png"></p>
<p><strong>Image Source</strong>: <a href="https://hikingartist.com/2012/01/03/cat-and-dog-online-2-0/" target="_blank">https://hikingartist.com/2012/01/03/cat-and-dog-online-2-0/</a></p>
<h2>Offer Answer <code>with</code><strong> Identity Check</strong></h2>
<p>The trust base is the Browser.</p>
<pre>             +----------------+    Unspecified    +----------------+
             |                |      protocol     |                |
             |    Signaling   |&lt;-----------------&gt;|    Signaling   |
             |    Server      |  (SIP, XMPP, ...) |    Server      |
             |                |                   |                |
             +----------------+                   +----------------+
                      ^                                   ^
                      |                                   |
                HTTPS |                                   | HTTPS
                      |                                   |
                      |                                   |
                      v                                   v
                   JS API                               JS API
             +-----------+                             +-----------+
             |           |             Media           |           |
       Alice |  Browser  |&lt;---------------------------&gt;|  Browser  | Bob
             |           |           DTLS+SRTP         |           |
             +-----------+                             +-----------+
                   ^      ^--+                      +--^     ^
                   |         |                      |        |
                   v         |                      |        v
             +-----------+   |                      |  +-----------+
             |           |&lt;-------------------------+  |           |
             |   IdP1    |   |                         |    IdP2   |
             |           |   +------------------------&gt;|           |
             +-----------+                             +-----------+
                   A federated call with IdP-based identity</pre>
<p>The following two slides are from EKR IETF Presentation mentioned above</p>
<h3><strong>Offer + Identity</strong></h3>
<p><img style="max-width: 624.00px" src="img/76a473e62e8295bc.png"></p>
<h3><strong>Answer + Identity</strong></h3>
<p><img style="max-width: 624.00px" src="img/7d1f3adde43daac0.png"></p>
<h2><strong>Media/Data Encryption is mandatory: SRTP / DTLS</strong></h2>
<ul>
<li>DTLS-SRTP: DTLS and Certificate based key.</li>
<li>SDES-SRTP &#34;MUST NOT implement&#34; according IETF 87</li>
</ul>
<aside class="warning"><p><strong>Important</strong>:  SDES-SRTP is obsoleted, mainly because to avoid any surveillance possibility. This was a design decision, and it could add interop issues with legacy systems!</p>
</aside>
<aside class="special"><p><strong>Note: Identity is a must!</strong> We don&#39;t trust fully anymore in the signaling provider. Earlier, in SDES-SRTP case we have trusted in signaling service provider, and assumed that it is authenticating the parties in the communication in some form. </p>
<p><em>Be aware that WebRTC designed to use E2E encryption, and without Identity validation security is not complete and leaky(!), this way it is extremely important to validate the Peers Identity.</em></p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Multipoint (SFU/MCU, Media Server)" duration="5">
        <h2><img style="max-width: 497.00px" src="img/aeeab6fb604bba76.png"></h2>
<p><strong>Image Source</strong>: Emil Ivov (<a href="https://jitsi.org/" target="_blank">Jitsi</a> /<a href="https://www.atlassian.com" target="_blank">Atlassian</a>)</p>
<h2><strong>Topologies</strong></h2>
<p>Topologies could vary and follow the Star or Mesh  or a mixed (e.g. interconnected stars, etc.) topology patterns.</p>
<h2><strong>Multipoint</strong></h2>
<p>Communication between multiple (more than two) parties could be done in many different ways, each of them has different pros and contras and neither fits to all possible scenarios, so there is no ultimate best choice. You should choose that one, that fits the best to your Application usage, or maybe you should use a mix of them.</p>
<h3><strong>P2P / Full Mesh</strong></h3>
<p><strong>Strength</strong></p>
<ul>
<li>Security: Identities could be validated and so media source could validated in a cryptographic way. And of course media is encrypted between the peers</li>
<li>The most direct communication (probably with the best latency)</li>
<li>Simple P2P topology: No central media server needed</li>
<li>Flexible Video layouts on client side</li>
<li>Following the internet principle, to keep the most intelligence and load on edge of the network</li>
</ul>
<p><strong>Weakness</strong></p>
<ul>
<li>Does not scale for a large conference N * (N-1) connection</li>
<li>Multiple stream (May drain your Mobile&#39;s battery fast.)</li>
</ul>
<h3><strong>Mixer / MCU</strong></h3>
<p>Multipoint Control Unit (MCU)</p>
<p><strong>Strength</strong></p>
<ul>
<li>Interoperability: Interworking, Transcoding between different codecs, DTMF inband/signaling etc.</li>
<li>Best interoperability with legacy systems</li>
<li>1 stream received (Draining slower your Mobile battery. Especially if mobile supports only 1 HW video en/de-coding.)</li>
<li>Composed Video Stream Recording on Server Side</li>
</ul>
<p><strong>Weakness </strong></p>
<ul>
<li>CPU intensive: decrypt + decode + compose + encode + encrypt</li>
<li>Transcoding/Size/Compose takes time and adds latency</li>
<li>Central huge CPU/GPU capacity is needed (Scaling?)</li>
<li>Video Image composed in central point , may limited layouts or interaction</li>
<li>Media is decrypted on Server side. We have to trust in a central component. (Possible leak.)</li>
<li>More complex than the P2P communication, because a Central component is needed</li>
</ul>
<h3><strong>SFU</strong></h3>
<p>Selective Forwarding Unit (SFU)</p>
<p>Used usually with Simulcast or Scalable Video Codec.</p>
<p><strong>Strength</strong></p>
<ul>
<li>Could scale for large conference participants</li>
<li>Could be used for low latency video streaming</li>
<li>Server Side Recording possible but needs post processing</li>
</ul>
<p><strong>Weakness</strong></p>
<ul>
<li>Less CPU load (only decrypt + encrypt)</li>
<li>Media is decrypted on Server side. We have to trust in a central component. (Possible leak.)</li>
<li>More complex than the P2P communication, because a Central component is needed</li>
</ul>
<h2><strong>Some example open source projects:</strong></h2>
<ul>
<li><a href="https://mediasoup.org/" target="_blank">https://mediasoup.org</a></li>
<li><a href="https://www.kurento.org/" target="_blank">https://www.kurento.org</a></li>
<li><a href="https://janus.conf.meetecho.com/" target="_blank">https://janus.conf.meetecho.com</a></li>
<li><a href="https://jitsi.org/" target="_blank">https://jitsi.org</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Screen-Sharing" duration="5">
        <h2><strong>ScreenShare</strong></h2>
<p>Screen Sharing is about to capture and grab your entire screen, or just one window, or application video stream. You could grab this MediaStream using special mediaConstraints, but using the same GuM function that we used for capturing webcam (or other video source), so  <code>navigator.mediaDevices.getUserMedia(mediaConstraints)</code>.</p>
<p>You could find the videTrack in this Stream that represents the Video that the user want to share. And we could add this video track to the PeerConnection.  We could share it parallel to the other streams.</p>
<h2><strong>Security</strong></h2>
<p>Be aware that ScreenSharing  is violating the &#34;<a href="https://en.wikipedia.org/wiki/Same-origin_policy" target="_blank">Same-Origin</a>&#34; Web principle, and this way use it with care. According the mentioned risk, Chrome web browser made the design decision to allow only screensharing from a Chrome extension. Take it seriously, to share only if you fully trust the site. For more details read:</p>
<ul>
<li><a href="https://blog.mozilla.org/webrtc/share-browser-windows-entire-screen-sites-trust/" target="_blank">https://blog.mozilla.org/webrtc/share-browser-windows-entire-screen-sites-trust/</a></li>
</ul>
<h2><strong>Chrome Screen Share extension:</strong></h2>
<p>Chrome extension gives the best user experience with inline install. Installation of the extension is offered by the browser easily, with only one click.</p>
<p>Example extension: </p>
<ul>
<li><a href="https://github.com/otalk/getScreenMedia" target="_blank">https://github.com/otalk/getScreenMedia</a></li>
<li><a href="https://github.com/misi/knockplop-chrome-plugin" target="_blank">https://github.com/misi/knockplop-chrome-plugin</a></li>
</ul>
<p><strong>Read more about inline install</strong></p>
<ul>
<li><a href="https://developer.chrome.com/webstore/inline_installation" target="_blank">https://developer.chrome.com/webstore/inline_installation</a></li>
</ul>
<p><strong>Mozilla / Firefox</strong></p>
<p>It supports screensharing without plugins or extension. <br>(Earlier it was needed for a web site that want to use screensharing  to be listed on a central whitelist, but it is no longer needed.)</p>
<ul>
<li><a href="https://wiki.mozilla.org/Screensharing" target="_blank">https://wiki.mozilla.org/Screensharing</a></li>
</ul>
<p><strong>Implemented Spec</strong>:</p>
<ul>
<li><a href="http://fluffy.github.io/w3c-screen-share" target="_blank">http://fluffy.github.io/w3c-screen-share</a></li>
</ul>
<p>Example constraints:</p>
<p><strong>Screen</strong></p>
<pre><code>mediaConstraints = {
    video: {
        mediaSource: &#34;screen&#34;
    },
};</code></pre>
<p><strong>Window</strong></p>
<pre><code>mediaConstraints = {
  video: {
    mediaSource: &#34;window&#34;
  }
};</code></pre>
<p><strong>Application</strong></p>
<pre><code>mediaConstraints = {
  video: {
    mediaSource: &#34;application&#34;
  }
};</code></pre>
<h2><strong>Standard</strong></h2>
<p>Standard without implementation</p>
<ul>
<li><a href="https://www.w3.org/TR/screen-capture/" target="_blank">https://www.w3.org/TR/screen-capture/</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Data(Channel) API" duration="5">
        <p>The most of the normal Web Communication happens through the Client- Server model. You may ask if we have already for data communication WebSocket, AJAX etc. protocols, then why should we add again a new protocol? </p>
<p>The main difference is that the WebRTC Data API is <em>Peer-to-Peer / Client-to-Client</em> and not Client - Server!</p>
<p>The Data(Channel) API lets a web application send and receive generic application data in Peer-to-Peer(P2P) fashion. DataChannel represents a bi-directional communication channel between the two peers.</p>
<h2><strong>API</strong></h2>
<p><strong>Init options:</strong></p>
<pre><code>const dcInitOptions = {
        ordered: true,
        maxRetransmits: 65535,
        //maxPacketLifeTime: 65535,
        priority: &#34;low&#34;,
        binaryType: &#34;blob&#34;,
};</code></pre>
<p><strong>Create dataCahnnel (local)</strong></p>
<pre><code>var dc = pc.createDataChannel(&#34;chat&#34;,dcInitOptions);</code></pre>
<p><strong>OnDataChannel (remote)</strong></p>
<pre><code>pc.ondatachannel = function(event) {
  dc=event.channel;
};</code></pre>
<p><strong>Send</strong></p>
<pre><code>dc.send($data);</code></pre>
<p><strong>Receive</strong></p>
<pre><code>dc.onmessage = function(event) {
  //event.data
};</code></pre>
<h2><strong>Transport</strong></h2>
<p>At the time of writing this document the WebRTC  Data API  implementations use SCTP over DTLS as the transport protocol. If we look forward, then we can see that <a href="https://w3c.github.io/webrtc-quic" target="_blank">QUIC</a> seems to be the next general transport protocol that will be implemented, and because it contains all benefits that SCTP has (and even more), it could be in longer term the successor of the data transport. /Just for the correct history: during the early days of WebRTC there was also an implementation option in Chrome, to transport Data over RTP  (RtpDataChannels)/.</p>
<h2><strong>Establishment</strong></h2>
<p>The establishment of the DataChannel could happen two ways. </p>
<ol type="1" start="1">
<li>Through out-of-band way <br>In this case asymmetric connection properties could be used. The datachannel objects should be created on both side and Id&#39;s are negotiated out-of-band.</li>
<li>Through an in-band, auto negotiated way (<strong>default</strong>)<br>In this case if an established PeerConnnection creating a new datachannel, then with in-band auto-negotiation on remote peer side automatically a new DataChannel  object will be created with symmetric properties and with the same DataChannel ID. </li>
</ol>
<h2><strong>Operation types of the connection</strong></h2>
<ul>
<li>Different priority (<code>DataChannelPriority</code>)</li>
<li>Ordering (Ordered/Unordered) <code>ordered</code></li>
<li>Reliability modes /Reliable/Unreliable/ ( <code>MaxPacketLifeTime, MaxRetransmits</code> ) <br>Only one of these options could be used at the same time, and can not be used both simultaneously!</li>
</ul>
<h2><strong>Usage</strong></h2>
<p>It could be used perfectly for real time text or binary Data exchange, e.g chat or file share, gaming, etc.<br>Furthermore some Applications (because of privacy concerns) could also use it for signaling. After the very first offer-answer exchange, and so the PeerConnection establishment, it could be used for handling any further signaling communication.</p>
<aside class="special"><p><strong>Notice</strong>: An example of advanced massive P2P DataChannel usage is the WebTorrent protocol</p>
<ul>
<li><a href="https://webtorrent.io/" target="_blank">https://webtorrent.io/</a></li>
<li><a href="https://instant.io/" target="_blank">https://instant.io/</a></li>
</ul>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Summary of the Theory" duration="5">
        <p><img style="max-width: 624.00px" src="img/de4ee6652313dd7f.png"></p>
<p><strong>Image Source</strong>: <a href="http://art.fritsahlefeldt.com/photo/2045/Goal-is-closer-than-you-think-Color-illustration.html" target="_blank">http://art.fritsahlefeldt.com/photo/2045/Goal-is-closer-than-you-think-Color-illustration.html</a></p>
<h2><strong>WebRTC 1.0 is stable to build reliable service on it.</strong></h2>
<ul>
<li>Strong and wide community</li>
<li>Fast New market</li>
<li>3,5-4 Billion of potential Browsers</li>
<li>More than 1300+ Vendor and Project based on WebRTC</li>
<li>Wide support in browsers: Chrome,Firefox, Opera, Edge, Safari, etc.</li>
</ul>
<h2><strong>WebRTC - Next Version (NV)</strong></h2>
<p>Actual Focus is on finishing 1.0 and only after it move forward to WebRTC-NV.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 1: GetuserMedia (GuM)" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Get a MediaStream from your WebCam (promise)</li>
<li>MediaStream and MediaStreamTrack differences</li>
<li>How a browser asks for consent to access your (Web)Camera</li>
<li>Manipulate the video with CSS</li>
</ul>
<h2><strong>Lab1</strong></h2>
<p>You could find this simple sample code in <code>Lab1</code> directory</p>
<h2><strong>HTML Skeleton with an autoplay Video tag </strong></h2>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset=&#34;utf-8&#34;&gt;
    &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1&#34;&gt;

    &lt;title&gt;WebRTC CodeLab&lt;/title&gt;

    &lt;link rel=&#34;stylesheet&#34; href=&#34;css/main.css&#34; /&gt;
    &lt;link rel=&#34;icon&#34; href=&#34;img/favicon-flask.ico&#34; type=&#34;image/x-icon&#34;&gt;
    &lt;script src=&#34;https://cdnjs.cloudflare.com/ajax/libs/webrtc-adapter/6.1.0/adapter.js&#34; defer&gt;&lt;/script&gt;
    &lt;script src=&#34;js/main.js&#34; defer&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;WebRTC CodeLab&lt;/h1&gt;
    &lt;video autoplay&gt;&lt;/video&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre>
<h2><strong>JavaScript</strong></h2>
<p><strong>See</strong>: js/<strong>main.js</strong></p>
<pre><code>// Strict mode changes previously accepted &#34;bad syntax&#34; into real errors.
&#39;use strict&#39;;

const mediaStreamConstraints = {
  video: true,
};

var myStream;

navigator.mediaDevices.getUserMedia(mediaStreamConstraints)
.then(function(mediaStream) {
   /* use the stream */
   myStream=mediaStream;
   var video = document.querySelector(&#39;video&#39;);
   video.srcObject = mediaStream;
})
.catch(function(err) {
   /* handle the error */
  console.error(err);
});</code></pre>
<h2><strong>Manipulate with css</strong></h2>
<p><strong>main.css</strong></p>
<pre><code>video {
    filter:saturate(8) opacity(70%);
}</code></pre>
<aside class="special"><p><strong>Tip!</strong> Filter: <a href="https://www.w3schools.com/cssref/css3_pr_filter.asp" target="_blank">https://www.w3schools.com/cssref/css3_pr_filter.asp</a></p>
</aside>
<h2><strong>Bonus exercises:</strong></h2>
<ul>
<li>Try to use instead of <code>&lt;video autoplay&gt;</code> in index.html a Java Script in main.js <code>video.onloadedmetadata= (e) =&gt; {e.target.play();}</code></li>
<li>Try out on browser JS dev console:  <code>myStream.getVideoTracks()</code> <code>myStream.getAudioTracks() myStream.getTracks()[0]</code></li>
<li>Try to stop track <code>myStream.getTracks()[0].stop</code></li>
<li>Try out to add audio to constraint <code>const mediaStreamConstraints = {audio:true,  video: true};</code></li>
<li>Get Video width: <code>document.querySelector(&#39;video&#39;).videoWidth</code></li>
<li>Set video <code>width</code> and <code>max-width</code></li>
</ul>
<aside class="special"><p><strong>Note</strong>: </p>
<ul>
<li>MediaStream is synchronized group of MediaStreamTracks. </li>
<li>Even a single MediaStreamTrack can represent multi-channel content, such as stereo or 5.1 audio or stereoscopic video!</li>
<li>If you don&#39;t use autoplay or similar function to start playing the video, then you will see only one still picture.</li>
<li>Make sure your video element doesn&#39;t overflow its container. Add width and max-width to set a preferred size and a maximum size for the video. (The browser will calculate the height automatically.)</li>
</ul>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 2: GuM Constraints" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Find out the supported media constraints</li>
<li>Constraint sets Basic/Required and Advanced</li>
<li>Media Constraints  values: difference between <code>min</code>, <code>max</code>, <code>exact</code>, and <code>ideal</code></li>
<li>Rejected promises (e.g. with <code>OverconstrainedError)</code></li>
</ul>
<h2><strong>Lab2</strong></h2>
<p>You could find the completed Lab in <code>Lab2</code> directory. Play with the constraints (that are supported by browser) and try to add low and high values.</p>
<p>Check the lab JS code and try to modify it, and experience how video change according the constraint change. Start playing with the width and height.</p>
<h2><strong>Supported Constraints</strong></h2>
<p>Get the supported constraints list, that the browser supports.</p>
<pre><code>var supportedConstraints = navigator.mediaDevices.getSupportedConstraints();</code></pre>
<h2><strong>Constraints</strong></h2>
<h3><strong>Basic/Required, Advanced Constraint list</strong></h3>
<ul>
<li><strong>Basic/Required </strong>is a ConstraintSet that the Browser <em>MUST</em> to restrict the settings of the corresponding constrainable properties to the specified values or ranges of values.</li>
<li><strong>Advanced</strong>: is the list of ConstraintSets that the Browser <em>MUST</em> attempt to satisfy, in order, skipping only those that cannot be satisfied. The order of these ConstraintSets is significant. The browser <em>MUST</em> try to satisfy them in the order that is specified.</li>
</ul>
<p><strong>Example:</strong></p>
<pre><code>var constraints = {
    width: { min: 640, ideal: 1280 },
    height: { min: 480, ideal: 720 },
    advanced: [
      { width: 1920, height: 1280 },
      { aspectRatio: 1.3333333333 }
    ]
  };</code></pre>
<p><strong>In this example above, the browser </strong></p>
<ul>
<li>prefers if possible prefers 1920x1280 </li>
<li>if it is not possible then if possible then it prefers the ascpectRatio  4/3</li>
<li>But the Basic/Required constraints MUST be satisfied in all cases (width minimum 640,  and height 480, with &#34;gravity&#34; to ideal  width 1280 and ideal height 720).</li>
</ul>
<h3><strong>Constraints Values</strong></h3>
<ul>
<li><strong>Exact</strong>: The exact match of the value </li>
<li><strong>Min</strong>/<strong>Max</strong>: Specify a Range lower or higher barrier value</li>
<li><strong>Ideal</strong>: Ideal/prefered value, the browser tries to satisfy with some gravity to this value</li>
</ul>
<aside class="special"><p><strong>Note</strong>: Bare values are treated as <em>Exact</em> values.</p>
</aside>
<p><strong>Exact Ideal example:</strong></p>
<pre><code>var constraints = {
  video: {
    width: { exact: 640 },
    height: { ideal: 480 }
  }
}</code></pre>
<h3><strong>Further examples</strong></h3>
<p><strong>Framerate</strong></p>
<pre><code>var constraints = { 
  video: {
    frameRate: { 
      ideal: 10, 
      max: 15 
    } 
  }
};</code></pre>
<p><strong>Facing mode</strong></p>
<pre><code>// &#34;user&#34; / &#34;environment&#34; ( / &#34;left&#34; / &#34;right&#34; )
var constraints = {
  video: { 
    facingMode: &#34;user&#34;
  }
};</code></pre>
<h3><strong>OverconstrainedError</strong></h3>
<p>If browser could not satisfy the constraints then promise is rejected with an Overconstrained error. This error object contains the reason.</p>
<p>E.g. Try to add to your constraint a width value that your WebCam is not supporting and see the results on your browser&#39;s developer console log.</p>
<aside class="special"><p><strong>For more detailed definitions and examples</strong>: see the standard <a href="https://w3c.github.io/mediacapture-main" target="_blank">https://w3c.github.io/mediacapture-main</a></p>
</aside>
<h2><strong>Bonus Exercises</strong></h2>
<ul>
<li>Define an Constraint with advance constraintset with 1280x720 and 640x480</li>
<li>See a video track Settings/Constraints/Capabilities</li>
</ul>
<pre><code>track=document.querySelector(&#39;video&#39;).srcObject.getTracks()[0];
track.getConstraints();
track.getCapabilities();
track.getSettings();</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 3: GuM I/O Select" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Discovery available MediaDevices</li>
<li>Select Input Audio/Video Device</li>
<li>Select Output Audio Device</li>
</ul>
<h2><strong>Lab3</strong></h2>
<p>You could find the completed Lab in <code>Lab3</code> directory.</p>
<p>Select another input/output from the dropdown list to start media capture. </p>
<aside class="special"><p><strong>Tip</strong>: Try Lab3 on your <strong>mobile</strong> where multiple webcam (front/back) is available.</p>
</aside>
<h3><strong>EnumarateDevices </strong></h3>
<p>Enumarate all Media Devices,and it is added as an option to one of the three dropdown select inputs</p>
<ul>
<li>Input Audio </li>
<li>Input Video</li>
<li>Output Audio</li>
</ul>
<pre><code>navigator.mediaDevices.enumerateDevices()
  .then(function (devices){
    console.log(devices);
    devices.forEach(function(deviceInfo) {
      var option = document.createElement(&#39;option&#39;);
      option.value = deviceInfo.deviceId;
      if (deviceInfo.kind === &#39;audioinput&#39;) {
        option.text = deviceInfo.label ||
          &#39;Microphone &#39; + (audioInputSelect.length + 1);
        audioInputSelect.appendChild(option);
      } else if (deviceInfo.kind === &#39;audiooutput&#39;) {
        option.text = deviceInfo.label || &#39;Speaker &#39; +
          (audioOutputSelect.length + 1);
        audioOutputSelect.appendChild(option);
      } else if (deviceInfo.kind === &#39;videoinput&#39;) {
        option.text = deviceInfo.label || &#39;Camera &#39; +
          (videoInputSelect.length + 1);
        videoInputSelect.appendChild(option);
      }

    });
  })
  .catch(errorCallback);</code></pre>
<aside class="special"><p><strong>Note</strong>: To avoid any fingerprinting, the browser will not reveal all detailed information of the detected mediadevices until user not give consent to access a MediaDevice. This way instead of the name of the WebCam only Id&#39;s will be presented. (To avoid any mislead, if you test this feature don&#39;t use it parallel with persistent consent.)</p>
</aside>
<h3><strong>Select Audio Output</strong></h3>
<aside class="special"><p><strong>Note</strong>: </p>
<p>Audio Output is not part of the main media capture and stream API. It is defined in a separated specification: <a href="https://www.w3.org/TR/audio-output/" target="_blank">https://www.w3.org/TR/audio-output/</a></p>
</aside>
<p>Set output with function <code>setSinkID(mediaDeviceID)</code></p>
<pre><code>function outputSelected() {
  var audioOutputId = audioOutputSelect.value;
  video.setSinkId(audioOutputId);
};</code></pre>
<h3><strong>Select Audio/Video Input</strong></h3>
<p>We adjust the MediaConstraint, and set the <code>deviceId</code> as constraint to select the proper input device.</p>
<pre><code>function inputSelected() {
  if (window.mediaStream) {
    let tracks = window.mediaStream.getTracks();

    tracks.forEach(function(track) {
      track.stop();
    });
  };
  var audioInputId = audioInputSelect.value;
  var videoInputId = videoInputSelect.value;
  var mediaStreamConstraints = {
    audio: { deviceId: audioInputId ? {exact: audioInputId } : undefined },
    video: { deviceId: videoInputId ? {exact: videoInputId } : undefined }
  };</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 4: GuM Record" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Detect supported recording formats</li>
<li>Record a stream locally</li>
<li>Playback recording and make available for download</li>
</ul>
<h2><strong>Lab4</strong></h2>
<p>You could find the completed Lab in <code>Lab4</code> directory.</p>
<p>It this lab there are 4 buttons and one dropdown select element.</p>
<ol type="1" start="1">
<li>Use &#34;GetuserMedia&#34; button to start capturing your webCam MediaStream (give your consent to access webcam in the pop-up)</li>
<li>Select from the dropdown the format you prefer for the recording. (Only the supported formats will be listed in this select input.)</li>
<li>Use the &#34;Start Recording&#34; button and record your video message :-).</li>
<li>&#34;Stop Recording&#34;</li>
<li>Start &#34;Replay&#34; in another video element, and also add a Link where the recorded file could be downloaded.</li>
</ol>
<h2>MediaStream <strong>Recording API</strong></h2>
<aside class="special"><p><strong>Note</strong>: </p>
<p>MediaRecording is not part of the main media capture and stream api. It is defined in a separated specification: <a href="https://www.w3.org/TR/mediastream-recording/" target="_blank">https://www.w3.org/TR/mediastream-recording/</a></p>
</aside>
<h3><strong>Supported media recording formats</strong></h3>
<p>Create a dropdown list with the supported encoding format.</p>
<pre><code>var types = [&#34;video/webm\;codecs=vp9&#34;,
             &#34;video/webm\;codecs=vp8&#34;,
             &#34;video/webm\;codecs=daala&#34;,
             &#34;video/webm\;codecs=h264&#34;];

for (var i in types) {
  if (MediaRecorder.isTypeSupported(types[i])) {
    console.log(&#34;Yes, \&#34;&#34;+types[i] + &#34;\&#34; is probably supported..&#34;);
    var option = document.createElement(&#39;option&#39;);
    option.value = option.text = types[i];
    formatSelect.appendChild(option);
  } else {
    console.log(&#34;Unfortunately \&#34;&#34;+types[i] + &#34;\&#34; not yet supported. :(&#34;);
  };
};</code></pre>
<h3><strong>Start/Stop Recording</strong></h3>
<p>We construct the <code>MediaRecoderOption</code>. In our example we use only the <code>mimeType</code> option, that&#39;s value is coming from the selected encoding format.</p>
<h4><strong>MediaRecorderOptions</strong></h4>
<ul>
<li><strong>mimeType</strong>: The mime type you want to use as the recording container for the new MediaRecorder. The container and codec format(s) <a href="https://www.w3.org/TR/mediastream-recording/#biblio-rfc2046" target="_blank">[RFC2046]</a> for the recording, which may include any parameters that are defined for the format.</li>
<li><strong>audioBitsPerSecond</strong>: Aggregate target bits per second for encoding of the Audio track(s), if any.</li>
<li><strong>videoBitsPerSecond</strong>: Aggregate target bits per second for encoding of the Video track(s), if any.</li>
<li><strong>bitsPerSecond</strong>: Aggregate target bits per second for encoding of all Video and Audio Track(s) present</li>
</ul>
<p>After local MediaStream is already captured, we start recording with create and <code>start()</code> MediaRecorderObject and <code>stop()</code> this object at the recording end.</p>
<pre><code>var localStream;
var mediaRecorder;
var chunks = [];

//localStream set by getUserMedia

function record() {
  formatSelect.disabled = true;
  recordButton.disabled = true;
  var mediaRecorderOptions = {};
  mediaRecorderOptions.mimeType = formatSelect.value;
  try {
    mediaRecorder = new MediaRecorder(localStream, mediaRecorderOptions);
  } catch (e) {
    console.error(&#34;Error during mediarecorder creation using format(&#34; + format + &#34;): &#34; + e);
    alert(&#34;Error during mediarecorder creation using format(&#34; + format + &#34;)&#34;);
  }
  mediaRecorder.ondataavailable = dataAvailable;
  mediaRecorder.start(25); // collect 25ms of data
  stopButton.disabled = false;
};

function dataAvailable(e) {
  chunks.push(e.data);
};

function stop() {
  stopButton.disabled = true;
  mediaRecorder.stop();
  replayButton.disabled = false;
};</code></pre>
<h3><strong>Replay and Download</strong></h3>
<ol type="1" start="1">
<li>We create from the recorded 25 Seconds long recorded chunks a Blob object.</li>
<li>Get the URL from createObjectURL</li>
<li>Set this URL as the source of <code>video</code> replay element.</li>
<li>Create a link with the same URL and add this new anchor element to the document.</li>
</ol>
<pre><code>function replay() {
  vod.controls = true;
  var buffer = new Blob(chunks, {type: &#39;video/webm&#39;});
  var recordingUrl = window.URL.createObjectURL(buffer);
  vod.src = recordingUrl;
  //Add download link
  var a = document.createElement(&#39;a&#39;);
  var linkText = document.createTextNode(&#34;!!! Download Recording !!!&#34;);
  a.appendChild(linkText);
  a.href = recordingUrl;
  a.title = &#34;!!! Download Recording !!!&#34;
  a.download = &#39;recorded.webm&#39;;
  document.querySelector(&#39;#download&#39;).appendChild(a);
};</code></pre>
<h2><strong>Bonus Exercises</strong></h2>
<ul>
<li>Set in recorder options the Audio/Video or aggregated bit rate. </li>
<li>Check MediaRecorder Pause() and Resume() functions</li>
<li>Modify the media constraints as we learned in previous.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 5: GuM &#43; PC state" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Grab media (consent to access WebCam)</li>
<li>Setup a PeerConnection</li>
<li>Add a MediaStreamTrack to the established connection</li>
<li>Add STUN/TURN server and iceTransportPolicy</li>
<li>Setup RTP/RTCP and bundle policy</li>
</ul>
<h2><strong>Lab5</strong></h2>
<p>You could find the completed Lab in <code>Lab5</code> directory.</p>
<p>In this lab we will emulate a Peer to Peer call between two parties in one browser, and this way two <code>PeerConnection</code> object will be created pc1 and pc2.</p>
<p>You see three buttons &#34;GrabMedia&#34;, &#34;Call&#34;, and &#34;Hangup&#34;</p>
<ol type="1" start="1">
<li>Grab your local WebCam mediastream with &#34;GrabMedia&#34;</li>
<li>Establish a peerconnection with the &#34;Call&#34; button</li>
<li>And finally &#34;Hangup&#34; the call.</li>
</ol>
<p><strong>States and SDP</strong>:</p>
<p>See PeerConnection and ICE States and transitions and the offer/answer SDPs on Browser Developer Console (F12)</p>
<aside class="special"><p><strong>Tip!</strong>: Check during a call the browser&#39;s under the hood webrtc pages.</p>
<ul>
<li><strong>Chrome</strong> - chrome://webrtc-internals</li>
<li><strong>Firefox</strong> - about:webrtc</li>
</ul>
</aside>
<h3><strong>Call</strong></h3>
<p>Notice:</p>
<ul>
<li><strong>RTCConfiguration.iceServers</strong>: set your STUN and TURN servers</li>
<li><strong>We use Trickle ICE</strong>: We don&#39;t wait for detection of local candidates but send candidates as soon as they have been discovered.</li>
<li>We <strong>add tracks</strong> from localStream to PeerConnection pc1<br><code>localStream.getTracks().forEach(track =&gt; {pc1.addTrack(track, localStream);});</code></li>
<li>We receive media on PeerConnection pc2 when an <strong>ontrack</strong> (pc2.ontrack<strong>)</strong> event fired. Remote stream is the: <code>event.streams[0];</code></li>
</ul>
<pre><code>function call() {
  console.log(&#39;Call Start&#39;);

  callButton.disabled = true;

  var videoTracks = localStream.getVideoTracks();
  var audioTracks = localStream.getAudioTracks();
  if (audioTracks.length &gt; 0) {
    console.log(&#39;Actual Audio device: &#39; + audioTracks[0].label);
  }

  if (videoTracks.length &gt; 0) {
    console.log(&#39;Actual Video device: &#39; + videoTracks[0].label);
  }
  pc1 = new RTCPeerConnection(rtcConfig);
  pc2 = new RTCPeerConnection(rtcConfig);
  console.log(&#39;create peer connection objects&#39;);


  // signaling state
  var signalingStateLog1 = pc1.signalingState;
  var signalingStateLog2 = pc2.signalingState;

  pc1.onsignalingstatechange = function() {
    if (pc1) {
      signalingStateLog1 += &#34; -&gt; &#34; + pc1.signalingState;
      console.log(&#39;PC1 Sinaling: &#39; + signalingStateLog1);
    };
  };

  pc2.onsignalingstatechange = function() {
    if (pc2) {
      signalingStateLog2 += &#34; -&gt; &#34; + pc2.signalingState;
      console.log(&#39;PC2 Sinaling: &#39; + signalingStateLog2);
    };
  };


  // ice state
  var iceConnectionStateLog1 = pc1.iceConnectionState;
  var iceConnectionStateLog2 = pc2.iceConnectionState;

  pc1.oniceconnectionstatechange = function() {
    if (pc1) {
      iceConnectionStateLog1 += &#34; -&gt; &#34; + pc1.iceConnectionState
      console.log(&#39;PC1 ICE: &#39;+ iceConnectionStateLog1);
    };
  };

  pc2.oniceconnectionstatechange = function() {
    if (pc2) {
      iceConnectionStateLog2 += &#34; -&gt; &#34; + pc2.iceConnectionState
      console.log(&#39;PC2 ICE: &#39;+ iceConnectionStateLog2);
    };
  };


  pc1.onicecandidate = function (event){
     pc2.addIceCandidate(event.candidate);
     if(event.candidate) console.log(&#39;pc1 ICE Candidate: &#39;+event.candidate.candidate);
  }

  pc2.onicecandidate = function (event){
     pc1.addIceCandidate(event.candidate);
     if(event.candidate) console.log(&#39;pc2 ICE Candidate: &#39;+event.candidate.candidate);
  }


  pc2.ontrack = function(event) {
    remoteVideo.srcObject = event.streams[0];
    remoteVideo.onloadedmetadata = function(e) {
      remoteVideo.play();
    };
    hangupButton.disabled = false;
  }
  pc2.onnegotiationneeded = () =&gt; {
    try {
      console.log(&#34;pc2&#34;);
    } catch (err) {
      console.error(err);
    }
  };

  // add mediastream
  localStream.getTracks().forEach(track =&gt; {pc1.addTrack(track, localStream);});


  var offerOptions = {
    offerToReceiveAudio: 1,
    offerToReceiveVideo: 1
  };

 // init call
 pc1.createOffer(offerOptions).then( offer =&gt; {
   pc1.setLocalDescription(offer);
   pc2.setRemoteDescription(offer);
   console.log(&#39;Offer: &#39;+offer.sdp);
   pc2.createAnswer().then( answer =&gt; {
     pc2.setLocalDescription(answer);
     pc1.setRemoteDescription(answer);
     console.log(&#39;Answer: &#39;+answer.sdp);
   });
 });
}</code></pre>
<h3><strong>Offer-Answer</strong></h3>
<p><img style="max-width: 624.00px" src="img/4f1ff8d0dc38445c.png"></p>
<h3><strong>Hangup</strong></h3>
<p>Close PeerConnection and stop Tracks</p>
<pre><code>function hangup() {
  pc1.close();
  pc2.close();
  localStream.getTracks().forEach(track =&gt; { track.stop(); });
  grabButton.disabled = false;
  hangupButton.disabled = true;
}</code></pre>
<h2><strong>Bonus Exercises</strong></h2>
<ul>
<li>Use media constraints</li>
<li>Use STUN/TURN server: <code>var rtcConfig={iceServers: [{urls: &#39;stun:ltc.turn.geant.org&#39;}]}</code></li>
<li>Change Rtcconfig and set RTCIceTransportPolicy=&#34;Relay&#34;</li>
<li>Change Rtcconfig and set  RTCRtcpMuxPolicy=&#34;max-compat&#34;</li>
<li>Set in your Firefox browser a STUN/TURN Server<br><strong>about:config </strong></li>
</ul>
<pre><code>media.peerconnection.use_document_iceservers = false
Media.peerconnection.default_iceservers = [{urls: &#34;stun:ltc.turn.geant.org&#34;}]</code></pre>
<aside class="special"><p><strong>See more:</strong> about FireFox privacy options: <a href="https://wiki.mozilla.org/Media/WebRTC/Privacy" target="_blank">https://wiki.mozilla.org/Media/WebRTC/Privacy</a></p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 6: PC DataChannel Chat" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li><strong>No consent required</strong> for datachannel establishment (<strong>!</strong>)</li>
<li>Setup a PeerConnection with DataChannel</li>
</ul>
<h2><strong>Lab6</strong></h2>
<p>You could find the completed Lab in <code>Lab6</code> directory. <br></p>
<p>In this lab create a simple Peer to Peer chat application using DataChannel (DC). The same way as in previous Lab we establish a PeerConnection between the two parties in one browser. We have 2 <code>PeerConnection</code> object, pc1 and pc2. We name in this sample the two parties Alice (A) and Bob (B). The chat app is very simple, You will find for each participant one read-only text area for chat log, and an input text box where you could type your message.</p>
<aside class="special"><p><strong>Tip!</strong> During a call try to check the browser&#39;s under the hood webrtc page:</p>
<ul>
<li><strong>Chrome</strong> - chrome://webrtc-internals</li>
<li><strong>Firefox</strong> - about:webrtc</li>
</ul>
</aside>
<h3><strong>DataChannel (DC)</strong></h3>
<ul>
<li>We setup the DC with <code>pc1.createDataChanel()</code></li>
<li>After establishment of DC on pc2 side <code>pc.ondatachannel</code> event is triggered. (We add pc2.onmessage event handler)</li>
<li>We add pc1.onmessage event handler</li>
<li>If we press &#34;enter&#34; (keyCode===13) then we send input value with <code>dc.send(msg);</code></li>
</ul>
<pre><code>//DataChannel
var dc1;
var dc2;

/* (Un)Ordered / (Un)Reliable etc.
 * odrderd: If ordered set to false, data is allowed to be delivered out of order.
 * maxRetransmits: Limits the number of times a channel will retransmit data if not successfully delivered.
 * maxPacketLifeTime: Limits the time (in milliseconds) during which the channel will transmit or retransmit data if not acknowledged.
 * priority: very-low to high  See: https://www.w3.org/TR/webrtc/#dom-rtcprioritytype
 * binaryType: &#34;blob&#34; / &#34;arraybuffer&#34;
 */
const dcInitOptions = {
        ordered: true,
        maxRetransmits: 65535,
        //maxPacketLifeTime: 65535,
        priority: &#34;low&#34;,
        binaryType: &#34;blob&#34;,
};

dc1 = pc1.createDataChannel(&#34;chat&#34;,dcInitOptions);


dc1.onmessage = function(e) {
  log1.value += e.data;
};

pc2.ondatachannel = function(e) {
  dc2=e.channel;
  dc2.onmessage = function(e) {
    log2.value += e.data;
  }

};

input1.onkeypress = function (e) {
  if (e.keyCode === 13 || e.which === 13) {
    var msg = &#34;Alice: &#34;+input1.value+&#34;\n&#34;;
    log1.value += msg;
    dc1.send(msg);
    input1.value=&#34;&#34;;
  }
};

input2.onkeypress = function (e) {
  if (e.keyCode === 13 || e.which === 13) {
    var msg = &#34;Bob: &#34;+input2.value+&#34;\n&#34;;
    log2.value += msg;
    dc2.send(msg);
    input2.value=&#34;&#34;;
  }
};</code></pre>
<h2><strong>Bonus Exercises</strong></h2>
<ul>
<li>Examine dc1.readystate to make input1 readonly until dc is established</li>
<li>See dcInitOptions for (un)reliable and (un)ordered transmission etc.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 7: Nodejs Signaling Server (socket.io) Chat" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Setup a node.js based websocket server (What later could be used as Signaling server)</li>
<li>Send and Receive Data on WebSocket</li>
</ul>
<h2><strong>Lab7</strong></h2>
<p>You could find the completed Lab in <code>Lab7</code> directory.  In this lab we reuse the previous lab  simple chat application interface, but replacing the engine under the hood from datachannel to <code>socket.io</code>. </p>
<pre>cd lab7</pre>
<h3><strong>Copy your key/cert</strong></h3>
<p>Copy <code>cert.pem</code> and <code>prikey.pem</code></p>
<aside class="special"><p><strong>Tip</strong>:If you use vm and use let&#39;s encrypt cert then use ../utils/certcopy.sh</p>
</aside>
<p><code>See:</code><strong><code> package.json</code></strong><code> and see the two dependencies</code></p>
<pre><code>&#34;dependencies&#34;: {
  &#34;https&#34;: &#34;^1.0.0&#34;,
  &#34;socket.io&#34;: &#34;^2.0.4&#34;
}</code></pre>
<p>As alternative of <code>npm install</code> we use <code>yarn install</code> or as shortcut just simple:</p>
<p>yarn</p>
<h3>s<strong>erver.js</strong></h3>
<p>After socket.io client initiates a connection to the server, and sends a room message with room name, the server will join this client to the chosen room. Any further messages are broadcasted to all client in the room (except the sender).</p>
<pre><code>&#39;use strict&#39;;
const https = require(&#39;https&#39;);
const fs = require(&#39;fs&#39;);

const options = {
          key: fs.readFileSync(&#39;privkey.pem&#39;),
          cert: fs.readFileSync(&#39;cert.pem&#39;)
};
const httpsServer = https.createServer(options);
httpsServer.listen(8080);

const io = require(&#39;socket.io&#39;)(httpsServer);
io.on(&#39;connection&#39;, function(socket) {
  socket.on(&#39;room&#39;, (room) =&gt; {
    console.log(&#34;Room: &#34;+room);
    socket.join(room);
  });
  socket.on(&#39;message&#39;, (msg) =&gt; {
    console.log(&#34;Message: &#34;+msg);
    socket.broadcast.emit(&#39;message&#39;, msg);
  });
});</code></pre>
<h3><strong>Start Socket.io server</strong></h3>
<p>node server.js</p>
<pre>yarn start</pre>
<h3><strong>client.js</strong></h3>
<p>Connect to server and first send the &#34;room&#34; message to select and join to a room, and after it all further chat messages is broadcasted in this room.</p>
<pre><code>// Strict mode changes previously accepted &#34;bad syntax&#34; into real errors.
&#39;use strict&#39;;
const room = &#34;testroom&#34;;

var log1 = document.querySelector(&#34;#textArea1&#34;);
var log2 = document.querySelector(&#34;#textArea2&#34;);

var input1 = document.querySelector(&#34;#input1&#34;);
var input2 = document.querySelector(&#34;#input2&#34;);

var signaling = new URL(window.location.href);
signaling.port = 8080;
signaling.pathname = &#39;/&#39;;
console.log(&#39;Signaling Server: &#39;+signaling);

var socket1 = io(signaling.href);
var socket2 = io(signaling.href);

socket1.on(&#39;connect&#39;, () =&gt; {
  console.log(&#34;Alice / socket1 ready&#34;);
  socket1.emit(&#39;room&#39;,room);
});

socket2.on(&#39;connect&#39;, () =&gt; {
  console.log(&#34;Bob / socket2 ready&#34;);
  socket2.emit(&#39;room&#39;,room);
});


socket1.on(&#39;message&#39;, msg =&gt; {
  log1.value += msg;
});

socket2.on(&#39;message&#39;, msg =&gt; {
  log2.value += msg;
});


input1.onkeypress = function (e) {
  if (e.keyCode === 13 || e.which === 13) {
    var msg = &#34;Alice: &#34;+input1.value+&#34;\n&#34;;
    log1.value += msg;
    socket1.emit(&#39;message&#39;,msg);
    Input1.value = &#34;&#34;;
  }
}

input2.onkeypress = function (e) {
  if (e.keyCode === 13 || e.which === 13) {
    var msg = &#34;Bob: &#34;+input2.value+&#34;\n&#34;;
    log2.value += msg;
    socket2.emit(&#39;message&#39;,msg);
    Input2.value = &#34;&#34;;
  }
}</code></pre>
<h2><strong>Bonus Exercises</strong></h2>
<ul>
<li>Set chat input to readonly by default, and remove readonly attribute only after room message already sent.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Lab 8: Install KnockPlop" duration="5">
        <h2 class="checklist"><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>Install a simple room based VC service</li>
<li>This service is composited and combined mainly from the components thats have been presented earlier in this codelab.</li>
</ul>
<h2>Lab8</h2>
<p>KnockPlop is an Open Source basic multi participant peer-to-peer Web-Application that is based on WebRTC technology. It provides Audio and Video conferencing with Screen Sharing, Chat, and Web Torrent based File Sharing. The service is based on videorooms, and simply connects every participants the same room if they visiting the same URL. Private meetings based on random and long room id-s, and it has a very simple moodle integration too. </p>
<h3><strong>Main Features</strong></h3>
<ul>
<li>Simple room based VideoConferencing</li>
<li>Mute Audio/Video</li>
<li>Screen Sharing</li>
<li>Chat</li>
<li>File Sharing</li>
<li>Moodle integration</li>
</ul>
<p><a href="https://github.com/so010/knockplop" target="_blank">https://github.com/so010/knockplop</a></p>
<h2><strong>Install</strong></h2>
<p>Checkout from git</p>
<pre>git clone https://github.com/so010/knockplop.git
cd knockplop
yarn</pre>
<h3><strong>Copy configs</strong></h3>
<pre>cp server-config.js.dist server-config.js
cp client-config.js.dist client-config.js</pre>
<h3><strong>Setup Certificate</strong></h3>
<p>Copy cert.pem and prikey.pem and Setup cert and key in <code>server-config.js</code></p>
<aside class="special"><p><strong>Tip</strong>:If you use the codelab vm and use let&#39;s encrypt cert, then use ../utils/certcopy.sh</p>
</aside>
<h3><strong>Setup TURN Server</strong></h3>
<aside class="warning"><p><strong>Warning!</strong> To access turn.geant.org <a href="https://technical.edugain.org/status" target="_blank">eduGAIN</a> access required!</p>
</aside>
<p>Go to <a href="https://turn.geant.org" target="_blank">https://turn.geant.org</a> to acquire credential to TURN service:</p>
<ol type="1" start="1">
<li>Setup REST key in <code>server-config.js</code> for Time Limited Long Term Credential. </li>
<li>Or Setup the old fashioned Long Term Credential == User/Password Authentication and configure the <code>client-config.js</code> according to your credential.</li>
</ol>
<h3><strong>Start Server</strong></h3>
<pre>yarn start</pre>
<aside class="warning"><p><strong>Warning!</strong> May you need to stop other server listening on port 80/443, or reconfigure port in <code>server-config.js</code></p>
</aside>
<h2><strong>Bonus Exercises</strong></h2>
<ul>
<li><a href="https://demo.mediasoup.org/" target="_blank">https://demo.mediasoup.org/</a></li>
<li><a href="https://meet.jit.si/" target="_blank">https://meet.jit.si/</a></li>
<li><a href="https://janus.conf.meetecho.com/demos.html" target="_blank">https://janus.conf.meetecho.com/demos.html</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Congratulations" duration="5">
        <h2 class="checklist"><strong>What we&#39;ve covered</strong></h2>
<ul class="checklist">
<li>Grab your local WebCam Audio/Video Stream.</li>
<li>Get and Configure the Mediadevice supported parameters/constraints</li>
<li>Discover MediaDevices, specify Input/Output Mediadevice</li>
<li>Record localy a MediaStream using MediaRecorder API</li>
<li>Setup PeerConnection and howto follow it&#39;s states</li>
<li>Use DataChannel</li>
<li>Use a simple (socket.io based) Signaling Channel</li>
<li>Install KnockPlop</li>
</ul>
<h2><strong>Let&#39;s start to play and experience with WebRTC</strong></h2>
<p>Let&#39;s start making mistakes on WebRTC field..</p>
<aside class="special"><p>&#34;An expert is a person who has found out by his own painful experience all the mistakes that one can make in a very narrow field.&#34; <strong>Niels Bohr</strong></p>
</aside>
<p><img style="max-width: 624.00px" src="img/9c41e769923d48bd.png"></p>
<p><strong>Image Source: </strong><a href="https://hikingartist.files.wordpress.com/2015/04/perspectives-deep-water-square.jpg" target="_blank">https://hikingartist.files.wordpress.com/2015/04/perspectives-deep-water-square.jpg</a></p>
<h2><strong>WebRTC Demos and Samples</strong></h2>
<ul>
<li>Google: <a href="https://webrtc.github.io/samples/" target="_blank">https://webrtc.github.io/samples/</a></li>
<li>Mozilla: <a href="https://mozilla.github.io/webrtc-landing/" target="_blank">https://mozilla.github.io/webrtc-landing/</a></li>
<li>Muaz Kahn: <a href="https://www.webrtc-experiment.com/" target="_blank">https://www.webrtc-experiment.com/</a></li>
</ul>
<h2><strong>Learn more about related API-s</strong></h2>
<p>GetUserMedia API</p>
<ul>
<li>W3C: <a href="https://www.w3.org/TR/mediacapture-streams/" target="_blank">https://www.w3.org/TR/mediacapture-streams/</a></li>
<li>Mozilla Developers: <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia" target="_blank">developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia</a></li>
</ul>
<p>WebRTC API</p>
<ul>
<li>W3C: <a href="https://www.w3.org/TR/webrtc/" target="_blank">www.w3.org/TR/webrtc/</a></li>
<li>Mozilla Developers: <a href="https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection" target="_blank">developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection</a></li>
</ul>
<p>WebAudio API</p>
<ul>
<li>W3C: <a href="https://www.w3.org/TR/webaudio/" target="_blank">www.w3.org/TR/webaudio/</a></li>
<li>Mozilla Developers: <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API" target="_blank">developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API</a></li>
</ul>
<p>MediaStream Recorder API</p>
<ul>
<li>W3C: <a href="https://www.w3.org/TR/mediastream-recording/" target="_blank">www.w3.org/TR/mediastream-recording/</a></li>
<li>Mozilla Developers: <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder/MediaRecorder" target="_blank">developer.mozilla.org/en-US/docs/Web/API/MediaRecorder/MediaRecorder</a></li>
</ul>
<p>Media Capture from DOM Elements API</p>
<ul>
<li>W3C: <a href="https://www.w3.org/TR/mediacapture-fromelement/" target="_blank">www.w3.org/TR/mediacapture-fromelement/</a></li>
<li>Mozilla Developers: <a href="https://developer.mozilla.org/en-US/docs/Web/API/CanvasCaptureMediaStream" target="_blank">developer.mozilla.org/en-US/docs/Web/API/CanvasCaptureMediaStream</a></li>
</ul>
<p>Audio Output Devices API</p>
<ul>
<li>W3C: <a href="https://www.w3.org/TR/audio-output/" target="_blank">www.w3.org/TR/audio-output/</a></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Acknowledgements" duration="0">
        <h2><strong>Acknowledgements</strong></h2>
<p>The author would like to thank </p>
<ul>
<li>Luca De Cicco</li>
<li>Håvar Aambø Fosstveit</li>
<li>Damien FETIS</li>
<li>Bartlomiej Idzikowski</li>
<li>Csaba Bozóky</li>
<li>Zoltán Kerekes</li>
<li>János Kukk </li>
<li>Péter Szabó</li>
<li>László Szeder</li>
<li>Sándor Petőh</li>
<li>Szilárd Varga</li>
</ul>
<p>for doing several reviews on the various revisions of this codelab.</p>
<h2><strong>Thanks &amp; Questions..</strong></h2>
<p>If you find any bug or have any comment don&#39;t hesitate to open an issue here: <a href="https://github.com/misi/codelab/issues/new" target="_blank">https://github.com/misi/codelab/issues/new</a></p>
<p><img style="max-width: 624.00px" src="img/6904ebda49da73f4.png"></p>
<p><strong>Image Source</strong>: <a href="http://art.fritsahlefeldt.com/photo/1732/Scared-of-speaking-Color-illustration.html" target="_blank">http://art.fritsahlefeldt.com/photo/1732/Scared-of-speaking-Color-illustration.html</a></p>


      </google-codelab-step>
    
      <google-codelab-step label="Debugging Browsers" duration="0">
        <h3><strong>Firefox:</strong></h3>
<p><strong>about:webrtc</strong></p>
<p>Open the URL above to see the under the hood informations about the MediaStreams and PeerConnections</p>
<p><strong>Debug and Trace</strong></p>
<pre>export NSPR_LOG_FILE=/home/ehugg/tmp/nspr.log
export NSPR_LOG_MODULES=signaling:5,mtransport:5,timestamp:1
export R_LOG_LEVEL=9
export R_LOG_DESTINATION=stderr</pre>
<p><strong>ICE media log:</strong></p>
<p>For ICE/STUN/TURN: </p>
<ul>
<li>Set R_LOG_DESTINATION=stderr </li>
<li>Set R_LOG_LEVEL=3 (can be anything between 1 and 9) </li>
<li>Set R_LOG_VERBOSE=1 if you want to include the module name generating the message </li>
</ul>
<p>For &#34;signaling&#34; (SDP offer/answer handling) and media transport, we use the normal Mozilla logging infrastructure, which uses a comma-separated list of modules, each one with its indicated log level; for WebRTC, you&#39;ll be most interested in these: </p>
<ul>
<li>Set NSPR_LOG_MODULES=signaling:5,mtransport:5 </li>
<li>You can also add &#34;,timestamp:1&#34; to that list if you want each log message to include timestamps. </li>
</ul>
<h3><strong>Debug Chrome</strong></h3>
<p><strong>chrome://webrtc-internals</strong></p>
<p>Open the URL above to see the under the hood informations about the MediaStreams and PeerConnections</p>
<p><strong>Debug and Trace</strong></p>
<pre>google-chrome --enable-logging=stderr --v=4 --vmodule=*libjingle/*=9 --vmodule=*media/*=9</pre>
<p><strong>linux log file</strong>: .config/chromium/chrome_debug.log</p>
<p>Basic info: <a href="https://www.chromium.org/for-testers/enable-logging" target="_blank">https://www.chromium.org/for-testers/enable-logging</a></p>
<ul>
<li>a) <code>--vmodule=*source*/talk/*=3</code></li>
<li>b)  <code>--vmodule=*third_party/libjingle/*=3</code></li>
<li>c) <code>--vmodule=*libjingle/source/talk/*=3</code></li>
</ul>
<p><code>--enable-logging=stderr --log-level=3 --vmodule=*libjingle/*=3,*=0</code></p>


      </google-codelab-step>
    
  </google-codelab>

  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-114682180-1', 'auto');

    (function() {
      var gaCodelab = 'UA-114682180-1';
      if (gaCodelab) {
        ga('create', gaCodelab, 'auto', {name: 'codelab'});
      }

      var gaView;
      var parts = location.search.substring(1).split('&');
      for (var i = 0; i < parts.length; i++) {
        var param = parts[i].split('=');
        if (param[0] === 'viewga') {
          gaView = param[1];
          break;
        }
      }
      if (gaView && gaView !== gaCodelab) {
        ga('create', gaView, 'auto', {name: 'view'});
      }
    })();
  </script>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114682180-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-114682180-1');
</script>


</body>
</html>
